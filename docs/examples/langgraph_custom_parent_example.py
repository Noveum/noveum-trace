"""
LangGraph Custom Parent Span Example with Noveum Trace

This example demonstrates how to use metadata.noveum to:
1. Assign custom names to graph execution spans
2. Explicitly set parent-child relationships between two separate graphs

The example shows two independent LangGraph graphs where Graph 2
is explicitly made a child of Graph 1 using custom naming.

Graph 1: Data Collection Pipeline (3 nodes)
  - fetch_data â†’ validate_data â†’ store_data

Graph 2: Analysis Pipeline (3 nodes)
  - load_data â†’ analyze_data â†’ generate_report

Both graphs are executed separately but Graph 2 is explicitly
nested under Graph 1 in the trace hierarchy using parent_name.
"""

import os
from typing import TypedDict

from dotenv import load_dotenv
from langchain_core.messages import HumanMessage
from langchain_openai import ChatOpenAI
from langgraph.graph import END, StateGraph

from noveum_trace import init as noveum_init
from noveum_trace.integrations import NoveumTraceCallbackHandler

# Load environment variables
load_dotenv()


# =============================================================================
# GRAPH 1: DATA COLLECTION PIPELINE
# =============================================================================


class DataCollectionState(TypedDict):
    """State for data collection pipeline."""

    query: str
    raw_data: str
    validated: bool
    stored: bool
    error: str


def fetch_data_node(state: DataCollectionState) -> DataCollectionState:
    """Node 1: Fetch data from a source."""
    print("\nğŸ” [Graph 1] FETCH DATA NODE")
    print(f"   Query: {state['query']}")

    # Simulate data fetching with LLM
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.7)
    response = llm.invoke(
        [HumanMessage(content=f"Generate sample weather data for: {state['query']}")]
    )

    state["raw_data"] = response.content
    print(f"   âœ“ Fetched {len(response.content)} characters of data")
    return state


def validate_data_node(state: DataCollectionState) -> DataCollectionState:
    """Node 2: Validate fetched data."""
    print("\nâœ… [Graph 1] VALIDATE DATA NODE")

    # Simple validation check
    if state["raw_data"] and len(state["raw_data"]) > 10:
        state["validated"] = True
        state["error"] = ""
        print("   âœ“ Data validation passed")
    else:
        state["validated"] = False
        state["error"] = "Data too short or empty"
        print(f"   âœ— Data validation failed: {state['error']}")

    return state


def store_data_node(state: DataCollectionState) -> DataCollectionState:
    """Node 3: Store validated data."""
    print("\nğŸ’¾ [Graph 1] STORE DATA NODE")

    if state["validated"]:
        state["stored"] = True
        print("   âœ“ Data stored successfully")
    else:
        state["stored"] = False
        print(f"   âœ— Cannot store invalid data: {state['error']}")

    return state


def create_data_collection_graph() -> StateGraph:
    """Create Graph 1: Data Collection Pipeline."""
    workflow = StateGraph(DataCollectionState)

    # Add nodes
    workflow.add_node("fetch", fetch_data_node)
    workflow.add_node("validate", validate_data_node)
    workflow.add_node("store", store_data_node)

    # Set entry point and edges
    workflow.set_entry_point("fetch")
    workflow.add_edge("fetch", "validate")
    workflow.add_edge("validate", "store")
    workflow.add_edge("store", END)

    return workflow


# =============================================================================
# GRAPH 2: ANALYSIS PIPELINE
# =============================================================================


class AnalysisState(TypedDict):
    """State for analysis pipeline."""

    data: str
    insights: list[str]
    report: str
    recommendations: list[str]


def load_data_node(state: AnalysisState) -> AnalysisState:
    """Node 1: Load data for analysis."""
    print("\nğŸ“¥ [Graph 2] LOAD DATA NODE")
    print(f"   Loading {len(state['data'])} characters of data")
    print("   âœ“ Data loaded successfully")
    return state


def analyze_data_node(state: AnalysisState) -> AnalysisState:
    """Node 2: Analyze the data."""
    print("\nğŸ”¬ [Graph 2] ANALYZE DATA NODE")

    # Use LLM to analyze data
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.3)
    response = llm.invoke(
        [
            HumanMessage(
                content=f"Analyze this data and provide 3 key insights:\n\n{state['data'][:500]}"
            )
        ]
    )

    # Extract insights (simplified)
    insights = [
        line.strip()
        for line in response.content.split("\n")
        if line.strip() and len(line.strip()) > 10
    ][:3]

    state["insights"] = insights
    print(f"   âœ“ Generated {len(insights)} insights")

    return state


def generate_report_node(state: AnalysisState) -> AnalysisState:
    """Node 3: Generate final report."""
    print("\nğŸ“Š [Graph 2] GENERATE REPORT NODE")

    # Use LLM to create report
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.5)

    insights_text = "\n".join(f"- {insight}" for insight in state["insights"])

    response = llm.invoke(
        [
            HumanMessage(
                content=f"Create a brief report summarizing these insights and provide 2 recommendations:\n\n{insights_text}"
            )
        ]
    )

    state["report"] = response.content

    # Extract recommendations (simplified)
    recommendations = [
        line.strip()
        for line in response.content.split("\n")
        if "recommend" in line.lower()
    ][:2]

    state["recommendations"] = (
        recommendations if recommendations else ["No specific recommendations"]
    )

    print(f"   âœ“ Report generated ({len(state['report'])} characters)")
    print(f"   âœ“ Recommendations: {len(state['recommendations'])}")

    return state


def create_analysis_graph() -> StateGraph:
    """Create Graph 2: Analysis Pipeline."""
    workflow = StateGraph(AnalysisState)

    # Add nodes
    workflow.add_node("load", load_data_node)
    workflow.add_node("analyze", analyze_data_node)
    workflow.add_node("report", generate_report_node)

    # Set entry point and edges
    workflow.set_entry_point("load")
    workflow.add_edge("load", "analyze")
    workflow.add_edge("analyze", "report")
    workflow.add_edge("report", END)

    return workflow


# =============================================================================
# MAIN EXECUTION
# =============================================================================


def main():
    """
    Example showing custom graph names and explicit parent relationships.
    """
    print("=" * 80)
    print("ğŸ¯ LANGGRAPH CUSTOM PARENT SPAN EXAMPLE")
    print("=" * 80)

    # Initialize Noveum Trace
    noveum_init(
        project=os.getenv("NOVEUM_PROJECT", "test-project"),
        api_key=os.getenv("NOVEUM_API_KEY"),
        environment=os.getenv("NOVEUM_ENVIRONMENT", "dev"),
    )
    print("âœ… Noveum Trace initialized")

    # Create callback handler
    handler = NoveumTraceCallbackHandler(use_langchain_assigned_parent=True)
    print("âœ… Callback handler created")

    # Manually start a trace
    # This prevents auto-finishing so both graphs stay in the same trace
    handler.start_trace("data_pipeline_with_analysis")
    print("âœ… Trace started manually")

    # ==========================================================================
    # EXECUTE GRAPH 1: DATA COLLECTION
    # ==========================================================================

    print("\n" + "=" * 80)
    print("ğŸ“Š EXECUTING GRAPH 1: DATA COLLECTION PIPELINE (Parent)")
    print("=" * 80)

    # Create and compile Graph 1
    graph1 = create_data_collection_graph()
    app1 = graph1.compile()

    # Configure with custom name
    config_graph1 = {
        "callbacks": [handler],
        "metadata": {
            "noveum": {
                "name": "data_collection_graph",  # Custom name for Graph 1
            }
        },
        "tags": ["graph1", "data_collection"],
    }

    # Execute Graph 1
    initial_state_1: DataCollectionState = {
        "query": "Tokyo weather patterns",
        "raw_data": "",
        "validated": False,
        "stored": False,
        "error": "",
    }

    result1 = app1.invoke(initial_state_1, config=config_graph1)

    print("\nâœ… Graph 1 completed")
    print(f"   Validated: {result1['validated']}")
    print(f"   Stored: {result1['stored']}")

    # ==========================================================================
    # EXECUTE GRAPH 2: ANALYSIS
    # ==========================================================================

    print("\n" + "=" * 80)
    print("ğŸ“Š EXECUTING GRAPH 2: ANALYSIS PIPELINE (Child)")
    print("=" * 80)

    # Create and compile Graph 2
    graph2 = create_analysis_graph()
    app2 = graph2.compile()

    # Configure with custom name AND parent reference
    config_graph2 = {
        "callbacks": [handler],
        "metadata": {
            "noveum": {
                "name": "analysis_graph",  # Custom name for Graph 2
                "parent_name": "data_collection_graph",  # Reference to Graph 1
            }
        },
        "tags": ["graph2", "analysis"],
    }

    # Execute Graph 2 using data from Graph 1
    initial_state_2: AnalysisState = {
        "data": result1["raw_data"],  # Pass data from Graph 1
        "insights": [],
        "report": "",
        "recommendations": [],
    }

    result2 = app2.invoke(initial_state_2, config=config_graph2)

    print("\nâœ… Graph 2 completed")
    print(f"   Insights: {len(result2['insights'])}")
    print(f"   Report length: {len(result2['report'])} characters")

    # Manually end the trace
    handler.end_trace()
    print("\nâœ… Trace ended manually")

    # ==========================================================================
    # SUMMARY
    # ==========================================================================

    print("\n" + "=" * 80)
    print("âœ… EXAMPLE COMPLETED")
    print("=" * 80)

    print("\nğŸ“Š Trace Structure:")
    print("  Trace: data_pipeline_with_analysis")
    print("  â””â”€â”€ Span: data_collection_graph (Graph 1)")
    print("      â”œâ”€â”€ Span: fetch (node)")
    print("      â”‚   â””â”€â”€ Span: llm.gpt-4o-mini")
    print("      â”œâ”€â”€ Span: validate (node)")
    print("      â””â”€â”€ Span: store (node)")
    print("      â””â”€â”€ Span: analysis_graph (Graph 2) â† Child of Graph 1!")
    print("          â”œâ”€â”€ Span: load (node)")
    print("          â”œâ”€â”€ Span: analyze (node)")
    print("          â”‚   â””â”€â”€ Span: llm.gpt-4o-mini")
    print("          â””â”€â”€ Span: report (node)")
    print("              â””â”€â”€ Span: llm.gpt-4o-mini")

    print("\nğŸ’¡ Key Points:")
    print("   1. handler.start_trace() creates a trace and disables auto-finishing")
    print("   2. Both graphs stay within the same manually controlled trace")
    print("   3. Graph 1 uses metadata.noveum.name='data_collection_graph'")
    print("   4. Graph 2 uses metadata.noveum.parent_name='data_collection_graph'")
    print("   5. This creates an explicit parent-child relationship between graphs")
    print("   6. Each graph has multiple nodes that are automatically nested")
    print("   7. handler.end_trace() manually finishes the trace")

    print("\nğŸ“‹ Results:")
    print(f"   Graph 1 stored data: {result1['stored']}")
    print(f"   Graph 2 insights: {result2['insights']}")
    print(f"   Graph 2 recommendations: {result2['recommendations']}")

    print(f"\nğŸ” Handler state: {handler}")


if __name__ == "__main__":
    main()
