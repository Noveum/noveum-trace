{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Noveum Trace SDK Testing Notebook\n",
    "\n",
    "This notebook demonstrates the complete functionality of the Noveum Trace SDK installed from PyPI.\n",
    "\n",
    "## Features Tested:\n",
    "- Basic installation and setup\n",
    "- Environment variable configuration\n",
    "- Function tracing with decorators\n",
    "- LLM call tracing\n",
    "- Agent workflow tracing\n",
    "- Multi-agent systems\n",
    "- Tool tracing\n",
    "- Context managers\n",
    "- Streaming support\n",
    "- Integration examples\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 1: Install Required Dependencies\n",
    "\n",
    "First, we'll install noveum-trace from PyPI along with some additional dependencies for testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install noveum-trace from PyPI and testing dependencies\n",
    "%pip install noveum-trace python-dotenv openai anthropic\n",
    "%pip install --upgrade noveum-trace pip\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 2: Set Up Environment Variables\n",
    "\n",
    "Configure the necessary environment variables for the SDK to work properly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file if it exists\n",
    "# Note: Using robust path detection since __file__ is not available in Jupyter notebooks\n",
    "try:\n",
    "    # Try to get current working directory\n",
    "    current_dir = os.getcwd()\n",
    "    print(f\"ğŸ“ Current directory: {current_dir}\")\n",
    "    \n",
    "    # Look for .env file in current directory and parent directories\n",
    "    env_file_found = False\n",
    "    search_dir = current_dir\n",
    "    \n",
    "    for _ in range(5):  # Search up to 5 levels up\n",
    "        env_file = os.path.join(search_dir, '.env')\n",
    "        if os.path.exists(env_file):\n",
    "            print(f\"ğŸ“„ Found .env file: {env_file}\")\n",
    "            load_dotenv(env_file)\n",
    "            env_file_found = True\n",
    "            break\n",
    "        search_dir = os.path.dirname(search_dir)\n",
    "        if search_dir == os.path.dirname(search_dir):  # Reached root\n",
    "            break\n",
    "    \n",
    "    if not env_file_found:\n",
    "        print(\"â„¹ï¸  No .env file found - continuing without it\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸  Error loading .env file: {e}\")\n",
    "    print(\"â„¹ï¸  Continuing without .env file\")\n",
    "\n",
    "# Set up environment variables for testing\n",
    "# Replace with your actual API key or set in .env file\n",
    "if not os.getenv('NOVEUM_API_KEY'):\n",
    "    # For testing purposes, you can set a dummy API key\n",
    "    # In production, use your actual Noveum API key\n",
    "    os.environ['NOVEUM_API_KEY'] = 'noveum_API_KEY'\n",
    "    print(\"âš ï¸  Using dummy API key for testing. Set NOVEUM_API_KEY environment variable for production use.\")\n",
    "else:\n",
    "    print(\"âœ… NOVEUM_API_KEY found i\")\n",
    "\n",
    "# Optional: Set OpenAI API key for LLM examples\n",
    "if not os.getenv('OPENAI_API_KEY'):\n",
    "    print(\"â„¹ï¸  OPENAI_API_KEY not found. LLM examples will use mock responses.\")\n",
    "else:\n",
    "    print(\"âœ… OPENAI_API_KEY found in environment\")\n",
    "\n",
    "print(\"\\nğŸ“‹ Environment Variables Status:\")\n",
    "print(f\"NOVEUM_API_KEY: {'âœ“' if os.getenv('NOVEUM_API_KEY') else 'âœ—'}\")\n",
    "print(f\"OPENAI_API_KEY: {'âœ“' if os.getenv('OPENAI_API_KEY') else 'âœ—'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## ğŸ”„ FLUSH HELPER: Automatic Trace Sending\n",
    "\n",
    "To ensure all traces are sent immediately to your endpoint, we'll create a helper function that can be called after any traced operation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”„ FLUSH HELPER FUNCTIONS FOR IMMEDIATE TRACE SENDING\n",
    "\n",
    "def flush_traces(operation_name=\"Operation\"):\n",
    "    \"\"\"\n",
    "    Helper function to flush traces immediately to endpoint.\n",
    "    Call this after any traced operation to ensure traces are sent right away.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        noveum_trace.flush()\n",
    "        print(f\"ğŸ“¤ âœ… {operation_name} traces flushed successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"ğŸ“¤ âš ï¸  {operation_name} flush warning: {e}\")\n",
    "\n",
    "def auto_flush_decorator(func):\n",
    "    \"\"\"\n",
    "    Decorator that automatically flushes traces after function execution.\n",
    "    Use this for any function that contains traced operations.\n",
    "    \"\"\"\n",
    "    def wrapper(*args, **kwargs):\n",
    "        result = func(*args, **kwargs)\n",
    "        flush_traces(func.__name__)\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "# Test the flush helper\n",
    "print(\"ğŸ”§ Flush helper functions initialized\")\n",
    "print(\"ğŸ“‹ Usage:\")\n",
    "print(\"  - Call flush_traces('operation_name') after any traced operation\")\n",
    "print(\"  - Use @auto_flush_decorator on functions containing traced operations\")\n",
    "print(\"  - This ensures immediate trace sending to your endpoint\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 3: Initialize the SDK\n",
    "\n",
    "Initialize the Noveum Trace SDK with your project configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import noveum_trace\n",
    "from noveum_trace import trace, trace_agent, trace_llm, trace_tool\n",
    "import logging\n",
    "\n",
    "# Enable detailed logging to debug transport issues\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "transport_logger = logging.getLogger('noveum_trace.transport')\n",
    "transport_logger.setLevel(logging.DEBUG)\n",
    "ENDPOINT = \"https://api.noveum.ai/api\"\n",
    "\n",
    "# Initialize the SDK with proper endpoint configuration\n",
    "try:\n",
    "    # IMPORTANT: The SDK will append \"/v1/traces\" to your endpoint\n",
    "    # So \"https://noveum-trace.free.beeceptor.com\" becomes \"https://noveum-trace.free.beeceptor.com/v1/traces\"\n",
    "    noveum_trace.init(\n",
    "        api_key=os.getenv('NOVEUM_API_KEY'),\n",
    "        project=\"jupyter-test-project\", \n",
    "        environment=\"development\",\n",
    "        endpoint=ENDPOINT,  # SDK will add /v1/traces automatically\n",
    "        debug=True,  # Enable debug mode for testing\n",
    "        \n",
    "        # Transport configuration for better reliability\n",
    "        transport_config={\n",
    "            \"timeout\": 10,           # 10 second timeout\n",
    "            \"retry_attempts\": 2,     # Retry failed requests 2 times\n",
    "            \"batch_size\": 10,        # Smaller batches for demo\n",
    "            \"batch_timeout\": 2.0,    # Send batches every 2 seconds\n",
    "            \"compression\": False     # Disable compression for debugging\n",
    "        },\n",
    "        \n",
    "        # Tracing configuration\n",
    "        tracing_config={\n",
    "            \"sample_rate\": 1.0,      # Trace 100% of operations\n",
    "            \"capture_errors\": True,\n",
    "            \"capture_stack_traces\": True\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    print(\"âœ… Noveum Trace SDK initialized successfully!\")\n",
    "    print(\"ğŸ“Š Project: jupyter-test-project\")\n",
    "    print(\"ğŸ”§ Environment: development\") \n",
    "    print(f\"ğŸŒ Endpoint: {ENDPOINT}/v1/traces (auto-appended)\")\n",
    "    print(\"ğŸ” Debug logging enabled - check console for HTTP request details\")\n",
    "    \n",
    "    # Get the current configuration to verify settings\n",
    "    config = noveum_trace.get_config()\n",
    "    print(f\"ğŸ“‹ Config verified - Endpoint: {config.transport.endpoint}\")\n",
    "    print(f\"ğŸ“¦ Batch size: {config.transport.batch_size}\")\n",
    "    print(f\"â±ï¸  Batch timeout: {config.transport.batch_timeout}s\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error initializing SDK: {e}\")\n",
    "    print(\"Continuing with demo - traces will be logged locally\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 5: LLM Call Tracing\n",
    "\n",
    "Test LLM call tracing with the `@trace_llm` decorator.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”„ FLUSH AFTER LLM CALL TRACING\n",
    "# This ensures the @trace_llm decorator traces are sent immediately\n",
    "\n",
    "flush_traces(\"LLM Call Tracing (call_language_model)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mock LLM responses for testing (replace with actual API calls if you have keys)\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "from noveum_trace import trace_llm\n",
    "\n",
    "def mock_openai_call(prompt: str, model: str = \"gpt-4\") -> str:\n",
    "    \"\"\"Mock OpenAI API call for testing.\"\"\"\n",
    "    responses = [\n",
    "        \"This is a mock response from the language model.\",\n",
    "        \"Here's a simulated AI response for testing purposes.\",\n",
    "        \"Mock LLM output to demonstrate tracing functionality.\"\n",
    "    ]\n",
    "    time.sleep(0.3)  # Simulate API call latency\n",
    "    return random.choice(responses)\n",
    "\n",
    "@trace_llm\n",
    "def call_language_model(prompt: str, model: str = \"gpt-4\") -> str:\n",
    "    \"\"\"Call a language model with tracing.\"\"\"\n",
    "    print(f\"ğŸ¤– Calling {model} with prompt: {prompt[:50]}...\")\n",
    "\n",
    "    # Use real OpenAI API if available, otherwise use mock\n",
    "    if os.getenv('OPENAI_API_KEY'):\n",
    "        try:\n",
    "            import openai\n",
    "            client = openai.OpenAI()\n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                max_tokens=100\n",
    "            )\n",
    "            return response.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸  OpenAI API call failed: {e}. Using mock response.\")\n",
    "            return mock_openai_call(prompt, model)\n",
    "    else:\n",
    "        print(\"ğŸ“ Using mock LLM response (no API key provided)\")\n",
    "        return mock_openai_call(prompt, model)\n",
    "\n",
    "# Test LLM tracing\n",
    "prompt = \"Explain the benefits of observability in AI systems.\"\n",
    "response = call_language_model(prompt)\n",
    "print(f\"\\nğŸ¯ LLM Response: {response}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”„ FLUSH AFTER ENHANCED LLM TRACING\n",
    "# This ensures all enhanced LLM traces (Anthropic, OpenAI, Google) are sent immediately\n",
    "\n",
    "flush_traces(\"Enhanced LLM Tracing (Anthropic + OpenAI + Google)\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 5.1: Enhanced LLM Tracing Examples\n",
    "\n",
    "Demonstrate various LLM tracing features including different providers, metadata, and advanced parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”„ FLUSH AFTER RETRIEVAL SYSTEM TRACING  \n",
    "# This ensures all @trace_retrieval decorator traces are sent immediately\n",
    "\n",
    "flush_traces(\"Retrieval System Tracing (Vector + Keyword + Hybrid)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced LLM Tracing Examples\n",
    "\n",
    "# Test different LLM providers with comprehensive metadata\n",
    "@trace_llm(provider=\"anthropic\", capture_tokens=True, estimate_costs=True)\n",
    "def call_anthropic(prompt: str, model: str = \"claude-3-haiku\") -> str:\n",
    "    \"\"\"Call Anthropic Claude with tracing.\"\"\"\n",
    "    print(f\"ğŸ§  Calling {model} with prompt: {prompt[:50]}...\")\n",
    "    \n",
    "    # Mock Anthropic response\n",
    "    time.sleep(0.4)\n",
    "    responses = [\n",
    "        \"Observability in AI systems provides critical insights into model behavior and performance.\",\n",
    "        \"Tracing AI workflows enables debugging, optimization, and compliance monitoring.\",\n",
    "        \"Comprehensive monitoring helps ensure AI system reliability and user trust.\"\n",
    "    ]\n",
    "    return random.choice(responses)\n",
    "\n",
    "# Test with custom metadata and tags\n",
    "@trace_llm(\n",
    "    provider=\"openai\", \n",
    "    capture_prompts=True, \n",
    "    capture_completions=True,\n",
    "    metadata={\"experiment\": \"demo\", \"version\": \"1.0\"},\n",
    "    tags={\"environment\": \"notebook\", \"user\": \"demo\"}\n",
    ")\n",
    "def call_llm_with_metadata(prompt: str, model: str = \"gpt-4\") -> str:\n",
    "    \"\"\"LLM call with custom metadata and tags.\"\"\"\n",
    "    print(f\"ğŸ“‹ Enhanced LLM call with metadata: {prompt[:40]}...\")\n",
    "    time.sleep(0.3)\n",
    "    return f\"Enhanced response for: {prompt[:20]}...\"\n",
    "\n",
    "# Test Google AI provider\n",
    "@trace_llm(provider=\"google\", capture_tokens=True, redact_pii=True)\n",
    "def call_google_ai(prompt: str, model: str = \"gemini-pro\") -> str:\n",
    "    \"\"\"Call Google AI with PII redaction.\"\"\"\n",
    "    print(f\"ğŸŸ¢ Calling {model} with PII protection: {prompt[:40]}...\")\n",
    "    time.sleep(0.5)\n",
    "    return \"Google AI response with PII redaction enabled for sensitive data handling.\"\n",
    "\n",
    "# Test various LLM providers\n",
    "print(\"ğŸ¤– Testing Enhanced LLM Tracing...\")\n",
    "\n",
    "anthropic_response = call_anthropic(\"What are the key benefits of AI observability?\")\n",
    "print(f\"\\nğŸ§  Anthropic Response: {anthropic_response}\")\n",
    "\n",
    "metadata_response = call_llm_with_metadata(\"Summarize the importance of AI monitoring\")\n",
    "print(f\"\\nğŸ“‹ Enhanced Response: {metadata_response}\")\n",
    "\n",
    "google_response = call_google_ai(\"How does tracing help with AI compliance?\")\n",
    "print(f\"\\nğŸŸ¢ Google AI Response: {google_response}\")\n",
    "\n",
    "print(\"\\nâœ… Enhanced LLM tracing completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”„ FLUSH AFTER ENHANCED MULTI-AGENT SYSTEM TRACING\n",
    "# This ensures all @trace_agent decorator traces are sent immediately\n",
    "\n",
    "flush_traces(\"Enhanced Multi-Agent System (Data Analyst + Content Curator + Synthesis + Orchestrator)\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 5.2: Retrieval System Tracing\n",
    "\n",
    "Test retrieval operations with the `@trace_retrieval` decorator for RAG systems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”„ FLUSH AFTER CONTEXT MANAGERS AND STREAMING\n",
    "# This ensures all context manager traces are sent immediately\n",
    "\n",
    "flush_traces(\"Context Managers and Streaming (trace_llm_call + trace_agent_operation + trace_operation + streaming)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the retrieval decorator\n",
    "from noveum_trace import trace_retrieval\n",
    "from typing import Dict, Any, Optional\n",
    "import time\n",
    "\n",
    "# Vector search with comprehensive tracing\n",
    "@trace_retrieval(\n",
    "    retrieval_type=\"vector_search\",\n",
    "    index_name=\"knowledge_base\",\n",
    "    capture_query=True,\n",
    "    capture_results=True,\n",
    "    capture_scores=True,\n",
    "    metadata={\"index_version\": \"v2.1\", \"embedding_model\": \"text-embedding-ada-002\"}\n",
    ")\n",
    "def vector_search(query: str, top_k: int = 5) -> Dict[str, Any]:\n",
    "    \"\"\"Perform vector search with tracing.\"\"\"\n",
    "    print(f\"ğŸ” Vector Search: Finding top {top_k} results for '{query}'\")\n",
    "    \n",
    "    # Simulate vector search\n",
    "    time.sleep(0.3)\n",
    "    \n",
    "    # Mock search results with scores\n",
    "    results = []\n",
    "    for i in range(top_k):\n",
    "        results.append({\n",
    "            \"document_id\": f\"doc_{i+1}\",\n",
    "            \"content\": f\"Relevant content for '{query}' - document {i+1}\",\n",
    "            \"score\": 0.95 - (i * 0.1),\n",
    "            \"metadata\": {\"source\": f\"source_{i+1}.pdf\", \"page\": i+1}\n",
    "        })\n",
    "    \n",
    "    search_result = {\n",
    "        \"query\": query,\n",
    "        \"total_results\": top_k,\n",
    "        \"results\": results,\n",
    "        \"search_time_ms\": 300,\n",
    "        \"index_stats\": {\"total_docs\": 10000, \"dimensions\": 1536}\n",
    "    }\n",
    "    \n",
    "    print(f\"âœ… Found {len(results)} relevant documents\")\n",
    "    return search_result\n",
    "\n",
    "# Keyword search with metadata capture\n",
    "@trace_retrieval(\n",
    "    retrieval_type=\"keyword_search\",\n",
    "    index_name=\"text_corpus\",\n",
    "    capture_metadata=True,\n",
    "    tags={\"search_type\": \"fulltext\", \"language\": \"en\"}\n",
    ")\n",
    "def keyword_search(query: str, filters: Optional[Dict] = None) -> Dict[str, Any]:\n",
    "    \"\"\"Perform keyword search with filtering.\"\"\"\n",
    "    print(f\"ğŸ” Keyword Search: '{query}' with filters: {filters}\")\n",
    "    \n",
    "    time.sleep(0.2)\n",
    "    \n",
    "    # Mock keyword search results\n",
    "    results = [\n",
    "        {\"doc_id\": \"kw_1\", \"title\": \"AI Observability Guide\", \"snippet\": \"...observability in AI...\"},\n",
    "        {\"doc_id\": \"kw_2\", \"title\": \"Tracing Best Practices\", \"snippet\": \"...tracing methodologies...\"},\n",
    "        {\"doc_id\": \"kw_3\", \"title\": \"Monitoring AI Systems\", \"snippet\": \"...monitoring strategies...\"}\n",
    "    ]\n",
    "    \n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"filters\": filters or {},\n",
    "        \"results\": results,\n",
    "        \"total_matches\": len(results)\n",
    "    }\n",
    "\n",
    "# Test retrieval operations\n",
    "print(\"ğŸ” Testing Retrieval System Tracing...\")\n",
    "\n",
    "# Test vector search\n",
    "vector_result = vector_search(\"benefits of AI observability\", top_k=3)\n",
    "print(f\"\\nğŸ” Vector Search Results: {len(vector_result['results'])} documents\")\n",
    "\n",
    "# Test keyword search with filters\n",
    "keyword_result = keyword_search(\"AI monitoring\", filters={\"category\": \"technical\", \"year\": 2024})\n",
    "print(f\"\\nğŸ” Keyword Search Results: {keyword_result['total_matches']} matches\")\n",
    "\n",
    "print(\"\\nâœ… Retrieval tracing completed!\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 6.1: Enhanced Multi-Agent System\n",
    "\n",
    "Test advanced multi-agent workflows with specialized agents and complex coordination patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Multi-Agent System Examples\n",
    "# Import required types to ensure they're available in this cell\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "# Specialized agents with different roles and capabilities\n",
    "@trace_agent(\n",
    "    agent_id=\"data_analyst\",\n",
    "    role=\"analyst\",\n",
    "    agent_type=\"specialist\",\n",
    "    capabilities=[\"data_analysis\", \"statistical_modeling\", \"visualization\"],\n",
    "    capture_reasoning=True,\n",
    "    metadata={\"specialization\": \"quantitative_analysis\", \"confidence_threshold\": 0.8}\n",
    ")\n",
    "def data_analyst_agent(data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Specialized data analysis agent.\"\"\"\n",
    "    print(f\"ğŸ“Š Data Analyst: Analyzing dataset with {len(data.get('samples', []))} samples\")\n",
    "    \n",
    "    time.sleep(0.5)\n",
    "    \n",
    "    # Mock data analysis\n",
    "    analysis = {\n",
    "        \"agent_id\": \"data_analyst\",\n",
    "        \"analysis_type\": \"quantitative\",\n",
    "        \"findings\": {\n",
    "            \"data_quality\": 0.92,\n",
    "            \"pattern_confidence\": 0.87,\n",
    "            \"anomalies_detected\": 3,\n",
    "            \"recommendations\": [\n",
    "                \"Data quality is high with 92% confidence\",\n",
    "                \"3 anomalies detected requiring investigation\",\n",
    "                \"Statistical patterns show strong correlation\"\n",
    "            ]\n",
    "        },\n",
    "        \"reasoning_steps\": [\n",
    "            \"Loaded and validated input data\",\n",
    "            \"Applied statistical analysis methods\", \n",
    "            \"Identified patterns and anomalies\",\n",
    "            \"Generated confidence-based recommendations\"\n",
    "        ],\n",
    "        \"processing_time\": 0.5\n",
    "    }\n",
    "    \n",
    "    print(f\"âœ… Analysis complete: {analysis['findings']['data_quality']:.2f} quality score\")\n",
    "    return analysis\n",
    "\n",
    "@trace_agent(\n",
    "    agent_id=\"content_curator\",\n",
    "    role=\"curator\",\n",
    "    agent_type=\"content_specialist\", \n",
    "    capabilities=[\"content_filtering\", \"quality_assessment\", \"summarization\"],\n",
    "    capture_tools=True\n",
    ")\n",
    "def content_curator_agent(content_list: List[Dict]) -> Dict[str, Any]:\n",
    "    \"\"\"Content curation and quality assessment agent.\"\"\"\n",
    "    print(f\"ğŸ“ Content Curator: Processing {len(content_list)} content items\")\n",
    "    \n",
    "    time.sleep(0.4)\n",
    "    \n",
    "    # Mock content curation using tools\n",
    "    high_quality_content = []\n",
    "    for i, content in enumerate(content_list):\n",
    "        if i < 3:  # Mock: keep first 3 as high quality\n",
    "            high_quality_content.append({\n",
    "                **content,\n",
    "                \"quality_score\": 0.9 - (i * 0.05),\n",
    "                \"curation_reason\": \"Meets quality standards\"\n",
    "            })\n",
    "    \n",
    "    curation_result = {\n",
    "        \"agent_id\": \"content_curator\",\n",
    "        \"input_count\": len(content_list),\n",
    "        \"curated_count\": len(high_quality_content),\n",
    "        \"curated_content\": high_quality_content,\n",
    "        \"tools_used\": [\"quality_scorer\", \"content_filter\", \"summarizer\"],\n",
    "        \"curation_metrics\": {\n",
    "            \"retention_rate\": len(high_quality_content) / len(content_list),\n",
    "            \"average_quality\": sum(item[\"quality_score\"] for item in high_quality_content) / len(high_quality_content)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(f\"âœ… Curated {len(high_quality_content)}/{len(content_list)} items\")\n",
    "    return curation_result\n",
    "\n",
    "# Test the enhanced multi-agent system\n",
    "print(\"ğŸ¤– Testing Enhanced Multi-Agent System...\")\n",
    "\n",
    "# Mock data for demonstration\n",
    "sample_data = {\"samples\": [f\"sample_{i}\" for i in range(100)]}\n",
    "sample_content = [\n",
    "    {\"id\": 1, \"title\": \"AI Observability\", \"content\": \"Content about observability\"},\n",
    "    {\"id\": 2, \"title\": \"Tracing Systems\", \"content\": \"Content about tracing\"},\n",
    "    {\"id\": 3, \"title\": \"Monitoring Tools\", \"content\": \"Content about monitoring\"},\n",
    "    {\"id\": 4, \"title\": \"Low Quality\", \"content\": \"Poor content\"}\n",
    "]\n",
    "\n",
    "# Test individual agents\n",
    "analyst_result = data_analyst_agent(sample_data)\n",
    "print(f\"\\nğŸ“Š Data Analysis: {analyst_result['findings']['data_quality']:.2f} quality score\")\n",
    "\n",
    "curator_result = content_curator_agent(sample_content)\n",
    "print(f\"\\nğŸ“ Content Curation: {curator_result['curated_count']}/{curator_result['input_count']} items retained\")\n",
    "\n",
    "print(\"\\nâœ… Enhanced multi-agent system testing completed!\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 7.1: Context Managers and Streaming\n",
    "\n",
    "Test context managers for inline tracing and streaming LLM responses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import context managers and streaming features\n",
    "from noveum_trace import (\n",
    "    trace_llm_call, trace_agent_operation, trace_operation, \n",
    "    streaming_llm, trace_streaming, ThreadContext\n",
    ")\n",
    "from typing import Dict, Any, Iterator\n",
    "\n",
    "# Context Manager Examples - Inline Tracing\n",
    "\n",
    "def process_user_query_with_context_managers(user_input: str) -> str:\n",
    "    \"\"\"Demonstrate inline tracing with context managers.\"\"\"\n",
    "    print(f\"ğŸ”„ Processing user query: '{user_input[:40]}...'\")\n",
    "    \n",
    "    # Some preprocessing (not traced)\n",
    "    cleaned_input = user_input.strip().lower()\n",
    "    \n",
    "    # Trace just the LLM call using context manager\n",
    "    with trace_llm_call(model=\"gpt-4\", provider=\"openai\", operation=\"query_processing\") as span:\n",
    "        print(\"ğŸ¤– Making LLM call within context manager...\")\n",
    "        time.sleep(0.4)\n",
    "        \n",
    "        # Mock LLM response\n",
    "        response = f\"Processed response for: {cleaned_input[:30]}...\"\n",
    "        \n",
    "        # Add custom attributes to the span\n",
    "        span.set_attributes({\n",
    "            \"llm.input_length\": len(cleaned_input),\n",
    "            \"llm.output_length\": len(response),\n",
    "            \"llm.processing_type\": \"query_understanding\"\n",
    "        })\n",
    "        \n",
    "        print(f\"âœ… LLM response generated: {len(response)} characters\")\n",
    "    \n",
    "    # Post-processing (not traced)\n",
    "    final_response = f\"Final: {response}\"\n",
    "    print(f\"ğŸ“¤ Final response: {final_response[:50]}...\")\n",
    "    \n",
    "    return final_response\n",
    "\n",
    "# Agent operation context manager\n",
    "def agent_task_with_context_manager(task: str) -> Dict[str, Any]:\n",
    "    \"\"\"Demonstrate agent operation tracing with context manager.\"\"\"\n",
    "    print(f\"ğŸ¤– Agent Task: '{task}'\")\n",
    "    \n",
    "    with trace_agent_operation(\n",
    "        agent_type=\"task_agent\", \n",
    "        operation=\"task_execution\",\n",
    "        capabilities=[\"task_planning\", \"execution\", \"monitoring\"]\n",
    "    ) as span:\n",
    "        print(\"âš™ï¸  Executing agent task...\")\n",
    "        time.sleep(0.3)\n",
    "        \n",
    "        # Mock agent work\n",
    "        result = {\n",
    "            \"task\": task,\n",
    "            \"status\": \"completed\",\n",
    "            \"steps_executed\": 5,\n",
    "            \"success_rate\": 0.95\n",
    "        }\n",
    "        \n",
    "        # Add agent-specific attributes\n",
    "        span.set_attributes({\n",
    "            \"agent.task_complexity\": \"medium\",\n",
    "            \"agent.steps_executed\": result[\"steps_executed\"],\n",
    "            \"agent.success_rate\": result[\"success_rate\"]\n",
    "        })\n",
    "        \n",
    "        print(f\"âœ… Agent task completed with {result['success_rate']:.1%} success rate\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Generic operation context manager (FIXED SYNTAX)\n",
    "def complex_operation_with_tracing() -> Dict[str, Any]:\n",
    "    \"\"\"Demonstrate generic operation tracing.\"\"\"\n",
    "    print(\"ğŸ”§ Starting complex operation...\")\n",
    "    \n",
    "    # CORRECT SYNTAX: trace_operation(operation_name, attributes=...)\n",
    "    with trace_operation(\"complex_data_processing\", \n",
    "                        attributes={\"operation_type\": \"data_pipeline\", \"complexity\": \"high\"}) as span:\n",
    "        # Step 1: Data loading\n",
    "        print(\"ğŸ“¥ Step 1: Loading data...\")\n",
    "        time.sleep(0.2)\n",
    "        span.set_attributes({\"step\": \"data_loading\", \"records_loaded\": 1000})\n",
    "        \n",
    "        # Step 2: Processing\n",
    "        print(\"âš™ï¸  Step 2: Processing data...\")\n",
    "        time.sleep(0.3)\n",
    "        span.set_attributes({\"step\": \"processing\", \"records_processed\": 950})\n",
    "        \n",
    "        # Step 3: Output\n",
    "        print(\"ğŸ“¤ Step 3: Generating output...\")\n",
    "        time.sleep(0.1)\n",
    "        span.set_attributes({\"step\": \"output\", \"records_output\": 950})\n",
    "        \n",
    "        result = {\n",
    "            \"operation\": \"complex_data_processing\",\n",
    "            \"input_records\": 1000,\n",
    "            \"processed_records\": 950,\n",
    "            \"success\": True\n",
    "        }\n",
    "        \n",
    "        print(\"âœ… Complex operation completed successfully\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Test context managers\n",
    "print(\"ğŸ”„ Testing Context Managers...\")\n",
    "\n",
    "print(\"\\\\n1ï¸âƒ£ Context Manager Examples:\")\n",
    "query_result = process_user_query_with_context_managers(\"What are the benefits of AI observability?\")\n",
    "\n",
    "agent_result = agent_task_with_context_manager(\"Analyze system performance metrics\")\n",
    "\n",
    "operation_result = complex_operation_with_tracing()\n",
    "\n",
    "print(\"\\\\nâœ… Context managers testing completed!\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 5.1: Enhanced LLM Tracing Examples\n",
    "\n",
    "Demonstrate various LLM tracing features including different providers, metadata, and advanced parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced LLM Tracing Examples\n",
    "\n",
    "# Test different LLM providers with comprehensive metadata\n",
    "@trace_llm(provider=\"anthropic\", capture_tokens=True, estimate_costs=True)\n",
    "def call_anthropic(prompt: str, model: str = \"claude-3-haiku\") -> str:\n",
    "    \"\"\"Call Anthropic Claude with tracing.\"\"\"\n",
    "    print(f\"ğŸ§  Calling {model} with prompt: {prompt[:50]}...\")\n",
    "    \n",
    "    # Mock Anthropic response\n",
    "    time.sleep(0.4)\n",
    "    responses = [\n",
    "        \"Observability in AI systems provides critical insights into model behavior and performance.\",\n",
    "        \"Tracing AI workflows enables debugging, optimization, and compliance monitoring.\",\n",
    "        \"Comprehensive monitoring helps ensure AI system reliability and user trust.\"\n",
    "    ]\n",
    "    return random.choice(responses)\n",
    "\n",
    "# Test with custom metadata and tags\n",
    "@trace_llm(\n",
    "    provider=\"openai\", \n",
    "    capture_prompts=True, \n",
    "    capture_completions=True,\n",
    "    metadata={\"experiment\": \"demo\", \"version\": \"1.0\"},\n",
    "    tags={\"environment\": \"notebook\", \"user\": \"demo\"}\n",
    ")\n",
    "def call_llm_with_metadata(prompt: str, model: str = \"gpt-4\") -> str:\n",
    "    \"\"\"LLM call with custom metadata and tags.\"\"\"\n",
    "    print(f\"ğŸ“‹ Enhanced LLM call with metadata: {prompt[:40]}...\")\n",
    "    time.sleep(0.3)\n",
    "    return f\"Enhanced response for: {prompt[:20]}...\"\n",
    "\n",
    "# Test Google AI provider\n",
    "@trace_llm(provider=\"google\", capture_tokens=True, redact_pii=True)\n",
    "def call_google_ai(prompt: str, model: str = \"gemini-pro\") -> str:\n",
    "    \"\"\"Call Google AI with PII redaction.\"\"\"\n",
    "    print(f\"ğŸŸ¢ Calling {model} with PII protection: {prompt[:40]}...\")\n",
    "    time.sleep(0.5)\n",
    "    return \"Google AI response with PII redaction enabled for sensitive data handling.\"\n",
    "\n",
    "# Test various LLM providers\n",
    "print(\"ğŸ¤– Testing Enhanced LLM Tracing...\")\n",
    "\n",
    "anthropic_response = call_anthropic(\"What are the key benefits of AI observability?\")\n",
    "print(f\"\\nğŸ§  Anthropic Response: {anthropic_response}\")\n",
    "\n",
    "metadata_response = call_llm_with_metadata(\"Summarize the importance of AI monitoring\")\n",
    "print(f\"\\nğŸ“‹ Enhanced Response: {metadata_response}\")\n",
    "\n",
    "google_response = call_google_ai(\"How does tracing help with AI compliance?\")\n",
    "print(f\"\\nğŸŸ¢ Google AI Response: {google_response}\")\n",
    "\n",
    "print(\"\\nâœ… Enhanced LLM tracing completed!\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 5.2: Retrieval System Tracing\n",
    "\n",
    "Test retrieval operations with the `@trace_retrieval` decorator for RAG systems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”„ FLUSH AFTER CORRECTED TRACE_OPERATION EXAMPLES\n",
    "# This ensures all corrected context manager traces are sent immediately\n",
    "\n",
    "flush_traces(\"Corrected trace_operation Examples (Fixed Syntax)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the retrieval decorator and missing typing imports\n",
    "from noveum_trace import trace_retrieval\n",
    "from typing import Dict, Any, Optional, List, Iterator\n",
    "\n",
    "# Vector search with comprehensive tracing\n",
    "@trace_retrieval(\n",
    "    retrieval_type=\"vector_search\",\n",
    "    index_name=\"knowledge_base\",\n",
    "    capture_query=True,\n",
    "    capture_results=True,\n",
    "    capture_scores=True,\n",
    "    metadata={\"index_version\": \"v2.1\", \"embedding_model\": \"text-embedding-ada-002\"}\n",
    ")\n",
    "def vector_search(query: str, top_k: int = 5) -> Dict[str, Any]:\n",
    "    \"\"\"Perform vector search with tracing.\"\"\"\n",
    "    print(f\"ğŸ” Vector Search: Finding top {top_k} results for '{query}'\")\n",
    "    \n",
    "    # Simulate vector search\n",
    "    time.sleep(0.3)\n",
    "    \n",
    "    # Mock search results with scores\n",
    "    results = []\n",
    "    for i in range(top_k):\n",
    "        results.append({\n",
    "            \"document_id\": f\"doc_{i+1}\",\n",
    "            \"content\": f\"Relevant content for '{query}' - document {i+1}\",\n",
    "            \"score\": 0.95 - (i * 0.1),\n",
    "            \"metadata\": {\"source\": f\"source_{i+1}.pdf\", \"page\": i+1}\n",
    "        })\n",
    "    \n",
    "    search_result = {\n",
    "        \"query\": query,\n",
    "        \"total_results\": top_k,\n",
    "        \"results\": results,\n",
    "        \"search_time_ms\": 300,\n",
    "        \"index_stats\": {\"total_docs\": 10000, \"dimensions\": 1536}\n",
    "    }\n",
    "    \n",
    "    print(f\"âœ… Found {len(results)} relevant documents\")\n",
    "    return search_result\n",
    "\n",
    "# Keyword search with metadata capture\n",
    "@trace_retrieval(\n",
    "    retrieval_type=\"keyword_search\",\n",
    "    index_name=\"text_corpus\",\n",
    "    capture_metadata=True,\n",
    "    tags={\"search_type\": \"fulltext\", \"language\": \"en\"}\n",
    ")\n",
    "def keyword_search(query: str, filters: Optional[Dict] = None) -> Dict[str, Any]:\n",
    "    \"\"\"Perform keyword search with filtering.\"\"\"\n",
    "    print(f\"ğŸ” Keyword Search: '{query}' with filters: {filters}\")\n",
    "    \n",
    "    time.sleep(0.2)\n",
    "    \n",
    "    # Mock keyword search results\n",
    "    results = [\n",
    "        {\"doc_id\": \"kw_1\", \"title\": \"AI Observability Guide\", \"snippet\": \"...observability in AI...\"},\n",
    "        {\"doc_id\": \"kw_2\", \"title\": \"Tracing Best Practices\", \"snippet\": \"...tracing methodologies...\"},\n",
    "        {\"doc_id\": \"kw_3\", \"title\": \"Monitoring AI Systems\", \"snippet\": \"...monitoring strategies...\"}\n",
    "    ]\n",
    "    \n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"filters\": filters or {},\n",
    "        \"results\": results,\n",
    "        \"total_matches\": len(results)\n",
    "    }\n",
    "\n",
    "# Hybrid search combining vector and keyword\n",
    "@trace_retrieval(\n",
    "    retrieval_type=\"hybrid_search\",\n",
    "    index_name=\"hybrid_index\",\n",
    "    capture_query=True,\n",
    "    capture_results=True,\n",
    "    capture_scores=True\n",
    ")\n",
    "def hybrid_search(query: str, alpha: float = 0.5) -> Dict[str, Any]:\n",
    "    \"\"\"Perform hybrid search combining vector and keyword search.\"\"\"\n",
    "    print(f\"ğŸ”— Hybrid Search: '{query}' with alpha={alpha}\")\n",
    "    \n",
    "    time.sleep(0.4)\n",
    "    \n",
    "    # Simulate hybrid search by combining both approaches\n",
    "    vector_results = vector_search(query, top_k=3)\n",
    "    keyword_results = keyword_search(query)\n",
    "    \n",
    "    # Mock hybrid ranking\n",
    "    hybrid_results = []\n",
    "    for i, result in enumerate(vector_results[\"results\"][:2]):\n",
    "        hybrid_results.append({\n",
    "            \"document_id\": result[\"document_id\"],\n",
    "            \"content\": result[\"content\"],\n",
    "            \"vector_score\": result[\"score\"],\n",
    "            \"keyword_score\": 0.8 - (i * 0.1),\n",
    "            \"combined_score\": (result[\"score\"] * alpha) + ((0.8 - i * 0.1) * (1 - alpha)),\n",
    "            \"source\": \"hybrid\"\n",
    "        })\n",
    "    \n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"alpha\": alpha,\n",
    "        \"results\": hybrid_results,\n",
    "        \"total_results\": len(hybrid_results),\n",
    "        \"search_strategy\": \"vector + keyword fusion\"\n",
    "    }\n",
    "\n",
    "# Test all retrieval operations\n",
    "print(\"ğŸ” Testing Retrieval System Tracing...\")\n",
    "\n",
    "# Test vector search\n",
    "vector_result = vector_search(\"benefits of AI observability\", top_k=3)\n",
    "print(f\"\\nğŸ” Vector Search Results: {len(vector_result['results'])} documents\")\n",
    "\n",
    "# Test keyword search with filters\n",
    "keyword_result = keyword_search(\"AI monitoring\", filters={\"category\": \"technical\", \"year\": 2024})\n",
    "print(f\"\\nğŸ” Keyword Search Results: {keyword_result['total_matches']} matches\")\n",
    "\n",
    "# Test hybrid search\n",
    "hybrid_result = hybrid_search(\"observability tracing systems\", alpha=0.7)\n",
    "print(f\"\\nğŸ”— Hybrid Search Results: {len(hybrid_result['results'])} combined results\")\n",
    "\n",
    "print(\"\\nâœ… Retrieval tracing completed!\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 6.1: Enhanced Multi-Agent System\n",
    "\n",
    "Test advanced multi-agent workflows with specialized agents and complex coordination patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Multi-Agent System Examples\n",
    "# Import missing typing if not already available\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "# Specialized agents with different roles and capabilities\n",
    "@trace_agent(\n",
    "    agent_id=\"data_analyst\",\n",
    "    role=\"analyst\",\n",
    "    agent_type=\"specialist\",\n",
    "    capabilities=[\"data_analysis\", \"statistical_modeling\", \"visualization\"],\n",
    "    capture_reasoning=True,\n",
    "    metadata={\"specialization\": \"quantitative_analysis\", \"confidence_threshold\": 0.8}\n",
    ")\n",
    "def data_analyst_agent(data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Specialized data analysis agent.\"\"\"\n",
    "    print(f\"ğŸ“Š Data Analyst: Analyzing dataset with {len(data.get('samples', []))} samples\")\n",
    "    \n",
    "    time.sleep(0.5)\n",
    "    \n",
    "    # Mock data analysis\n",
    "    analysis = {\n",
    "        \"agent_id\": \"data_analyst\",\n",
    "        \"analysis_type\": \"quantitative\",\n",
    "        \"findings\": {\n",
    "            \"data_quality\": 0.92,\n",
    "            \"pattern_confidence\": 0.87,\n",
    "            \"anomalies_detected\": 3,\n",
    "            \"recommendations\": [\n",
    "                \"Data quality is high with 92% confidence\",\n",
    "                \"3 anomalies detected requiring investigation\",\n",
    "                \"Statistical patterns show strong correlation\"\n",
    "            ]\n",
    "        },\n",
    "        \"reasoning_steps\": [\n",
    "            \"Loaded and validated input data\",\n",
    "            \"Applied statistical analysis methods\",\n",
    "            \"Identified patterns and anomalies\",\n",
    "            \"Generated confidence-based recommendations\"\n",
    "        ],\n",
    "        \"processing_time\": 0.5\n",
    "    }\n",
    "    \n",
    "    print(f\"âœ… Analysis complete: {analysis['findings']['data_quality']:.2f} quality score\")\n",
    "    return analysis\n",
    "\n",
    "@trace_agent(\n",
    "    agent_id=\"content_curator\",\n",
    "    role=\"curator\",\n",
    "    agent_type=\"content_specialist\",\n",
    "    capabilities=[\"content_filtering\", \"quality_assessment\", \"summarization\"],\n",
    "    capture_tools=True\n",
    ")\n",
    "def content_curator_agent(content_list: List[Dict]) -> Dict[str, Any]:\n",
    "    \"\"\"Content curation and quality assessment agent.\"\"\"\n",
    "    print(f\"ğŸ“ Content Curator: Processing {len(content_list)} content items\")\n",
    "    \n",
    "    time.sleep(0.4)\n",
    "    \n",
    "    # Mock content curation using tools\n",
    "    high_quality_content = []\n",
    "    for i, content in enumerate(content_list):\n",
    "        if i < 3:  # Mock: keep first 3 as high quality\n",
    "            high_quality_content.append({\n",
    "                **content,\n",
    "                \"quality_score\": 0.9 - (i * 0.05),\n",
    "                \"curation_reason\": \"Meets quality standards\"\n",
    "            })\n",
    "    \n",
    "    curation_result = {\n",
    "        \"agent_id\": \"content_curator\",\n",
    "        \"input_count\": len(content_list),\n",
    "        \"curated_count\": len(high_quality_content),\n",
    "        \"curated_content\": high_quality_content,\n",
    "        \"tools_used\": [\"quality_scorer\", \"content_filter\", \"summarizer\"],\n",
    "        \"curation_metrics\": {\n",
    "            \"retention_rate\": len(high_quality_content) / len(content_list),\n",
    "            \"average_quality\": sum(item[\"quality_score\"] for item in high_quality_content) / len(high_quality_content)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(f\"âœ… Curated {len(high_quality_content)}/{len(content_list)} items\")\n",
    "    return curation_result\n",
    "\n",
    "@trace_agent(\n",
    "    agent_id=\"synthesis_agent\",\n",
    "    role=\"synthesizer\",\n",
    "    agent_type=\"integration_specialist\", \n",
    "    capabilities=[\"multi_source_synthesis\", \"insight_generation\", \"report_creation\"],\n",
    "    capture_inputs=True,\n",
    "    capture_outputs=True\n",
    ")\n",
    "def synthesis_agent(analyst_data: Dict, curator_data: Dict, context: str) -> Dict[str, Any]:\n",
    "    \"\"\"Agent that synthesizes insights from multiple sources.\"\"\"\n",
    "    print(f\"ğŸ”— Synthesis Agent: Combining insights for context '{context}'\")\n",
    "    \n",
    "    time.sleep(0.6)\n",
    "    \n",
    "    # Synthesize insights from multiple agents\n",
    "    synthesis = {\n",
    "        \"agent_id\": \"synthesis_agent\",\n",
    "        \"context\": context,\n",
    "        \"input_sources\": [\"data_analyst\", \"content_curator\"],\n",
    "        \"synthesis_insights\": [\n",
    "            f\"Data quality score of {analyst_data['findings']['data_quality']:.2f} indicates reliable foundation\",\n",
    "            f\"Content curation retained {curator_data['curated_count']}/{curator_data['input_count']} high-quality items\",\n",
    "            \"Cross-analysis reveals consistent quality patterns across data and content\",\n",
    "            \"Synthesis confidence: High based on convergent evidence\"\n",
    "        ],\n",
    "        \"combined_metrics\": {\n",
    "            \"data_quality\": analyst_data['findings']['data_quality'],\n",
    "            \"content_quality\": curator_data['curation_metrics']['average_quality'],\n",
    "            \"overall_confidence\": (analyst_data['findings']['pattern_confidence'] + \n",
    "                                 curator_data['curation_metrics']['average_quality']) / 2\n",
    "        },\n",
    "        \"final_recommendation\": \"Proceed with high confidence based on quality convergence\"\n",
    "    }\n",
    "    \n",
    "    print(f\"âœ… Synthesis complete with {synthesis['combined_metrics']['overall_confidence']:.2f} confidence\")\n",
    "    return synthesis\n",
    "\n",
    "# Advanced orchestrator with dependency management\n",
    "@trace_agent(\n",
    "    agent_id=\"advanced_orchestrator\",\n",
    "    role=\"coordinator\", \n",
    "    agent_type=\"orchestrator\",\n",
    "    capabilities=[\"workflow_management\", \"dependency_resolution\", \"result_aggregation\"],\n",
    "    capture_reasoning=True,\n",
    "    metadata={\"orchestration_strategy\": \"parallel_with_dependencies\"}\n",
    ")\n",
    "def advanced_orchestrator(task: str, data_context: Dict) -> Dict[str, Any]:\n",
    "    \"\"\"Advanced orchestrator managing complex multi-agent workflows.\"\"\"\n",
    "    print(f\"ğŸ­ Advanced Orchestrator: Managing workflow for '{task}'\")\n",
    "    \n",
    "    # Phase 1: Parallel execution of independent agents\n",
    "    print(\"\\nğŸ”„ Phase 1: Parallel Agent Execution\")\n",
    "    \n",
    "    # Mock data for demonstration\n",
    "    sample_data = {\"samples\": [f\"sample_{i}\" for i in range(100)]}\n",
    "    sample_content = [\n",
    "        {\"id\": 1, \"title\": \"AI Observability\", \"content\": \"Content about observability\"},\n",
    "        {\"id\": 2, \"title\": \"Tracing Systems\", \"content\": \"Content about tracing\"},\n",
    "        {\"id\": 3, \"title\": \"Monitoring Tools\", \"content\": \"Content about monitoring\"},\n",
    "        {\"id\": 4, \"title\": \"Low Quality\", \"content\": \"Poor content\"}\n",
    "    ]\n",
    "    \n",
    "    # Execute agents in parallel (simulated)\n",
    "    analyst_result = data_analyst_agent(sample_data)\n",
    "    curator_result = content_curator_agent(sample_content)\n",
    "    \n",
    "    # Phase 2: Synthesis based on results\n",
    "    print(\"\\\\nğŸ”— Phase 2: Synthesis and Integration\")\n",
    "    synthesis_result = synthesis_agent(analyst_result, curator_result, task)\n",
    "    \n",
    "    # Final orchestration result\n",
    "    orchestration_result = {\n",
    "        \"task\": task,\n",
    "        \"orchestration_id\": \"adv_orch_001\",\n",
    "        \"phases\": {\n",
    "            \"analysis\": analyst_result,\n",
    "            \"curation\": curator_result, \n",
    "            \"synthesis\": synthesis_result\n",
    "        },\n",
    "        \"workflow_metrics\": {\n",
    "            \"total_agents\": 3,\n",
    "            \"execution_phases\": 2,\n",
    "            \"final_confidence\": synthesis_result[\"combined_metrics\"][\"overall_confidence\"],\n",
    "            \"workflow_success\": True\n",
    "        },\n",
    "        \"reasoning\": [\n",
    "            \"Initiated parallel execution of specialist agents\",\n",
    "            \"Data analyst provided quantitative insights\",\n",
    "            \"Content curator filtered and assessed quality\",\n",
    "            \"Synthesis agent combined multi-source insights\",\n",
    "            \"Workflow completed with high confidence\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    print(f\"\\\\nâœ… Advanced orchestration complete!\")\n",
    "    return orchestration_result\n",
    "\n",
    "# Test the enhanced multi-agent system\n",
    "print(\"ğŸ¤– Testing Enhanced Multi-Agent System...\")\n",
    "\n",
    "# Run the advanced workflow\n",
    "task = \"Comprehensive analysis of AI system observability data and content\"\n",
    "context_data = {\"domain\": \"ai_observability\", \"priority\": \"high\"}\n",
    "\n",
    "workflow_result = advanced_orchestrator(task, context_data)\n",
    "\n",
    "print(\"\\\\nğŸ­ Enhanced Multi-Agent Results:\")\n",
    "print(f\"Task: {workflow_result['task']}\")\n",
    "print(f\"Agents: {workflow_result['workflow_metrics']['total_agents']}\")\n",
    "print(f\"Phases: {workflow_result['workflow_metrics']['execution_phases']}\")\n",
    "print(f\"Final Confidence: {workflow_result['workflow_metrics']['final_confidence']:.2f}\")\n",
    "print(f\"Success: {workflow_result['workflow_metrics']['workflow_success']}\")\n",
    "\n",
    "print(\"\\\\nâœ… Enhanced multi-agent system testing completed!\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 7.1: Context Managers and Streaming\n",
    "\n",
    "Test context managers for inline tracing and streaming LLM responses.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## ğŸ¯ Comprehensive Demo Summary\n",
    "\n",
    "This notebook provides a **complete demonstration** of the Noveum Trace SDK capabilities:\n",
    "\n",
    "### ğŸ¨ All Available Decorators:\n",
    "- `@trace` - General purpose function tracing\n",
    "- `@trace_llm` - LLM call tracing with provider-specific features\n",
    "- `@trace_agent` - Agent workflow tracing with role-based capabilities\n",
    "- `@trace_tool` - Tool usage tracing with comprehensive metadata\n",
    "- `@trace_retrieval` - Retrieval operation tracing for RAG systems\n",
    "\n",
    "### ğŸ”„ Context Managers for Inline Tracing:\n",
    "- `trace_llm_call()` - LLM operations within existing functions\n",
    "- `trace_agent_operation()` - Agent tasks with custom attributes\n",
    "- `trace_operation()` - Generic operations with step-by-step tracking\n",
    "- `streaming_llm()` - Real-time streaming LLM response tracing\n",
    "- `ThreadContext()` - Conversation thread management\n",
    "\n",
    "### ğŸ¤– Multi-Agent System Features:\n",
    "- Basic orchestration patterns\n",
    "- Advanced multi-agent workflows with specialized roles\n",
    "- Dependency management between agents\n",
    "- Parallel execution and result synthesis\n",
    "- Agent capability tracking and reasoning capture\n",
    "\n",
    "### ğŸŒŠ Streaming & Real-time Features:\n",
    "- Token-by-token streaming trace capture\n",
    "- Real-time metrics (tokens/second, time to first token)\n",
    "- Stream metadata and performance analysis\n",
    "- Context-aware streaming within conversations\n",
    "\n",
    "### ğŸš€ Advanced SDK Features:\n",
    "- Auto-instrumentation for seamless integration\n",
    "- Manual trace/span creation for custom workflows\n",
    "- Batch processing and performance optimization\n",
    "- Configuration management and debugging tools\n",
    "- Comprehensive error handling and edge case testing\n",
    "\n",
    "### ğŸ“Š Integration Examples:\n",
    "- OpenAI API integration with cost estimation\n",
    "- Anthropic Claude integration with PII redaction\n",
    "- Google AI integration examples\n",
    "- RAG system integration (vector, keyword, hybrid search)\n",
    "- Multi-provider LLM support patterns\n",
    "\n",
    "This comprehensive demo showcases **every major feature** of the Noveum Trace SDK, making it the perfect reference for implementing observability in your AI applications! ğŸš€\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”„ FLUSH AFTER ENHANCED SDK INITIALIZATION AND ENDPOINT TESTING\n",
    "# This ensures the endpoint connectivity test traces are sent immediately\n",
    "\n",
    "flush_traces(\"Enhanced SDK Initialization and Endpoint Testing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import context managers and streaming features\n",
    "from noveum_trace import (\n",
    "    trace_llm_call, trace_agent_operation, trace_operation, \n",
    "    streaming_llm, trace_streaming, ThreadContext\n",
    ")\n",
    "\n",
    "# Context Manager Examples - Inline Tracing\n",
    "\n",
    "def process_user_query_with_context_managers(user_input: str) -> str:\n",
    "    \"\"\"Demonstrate inline tracing with context managers.\"\"\"\n",
    "    print(f\"ğŸ”„ Processing user query: '{user_input[:40]}...'\")\n",
    "    \n",
    "    # Some preprocessing (not traced)\n",
    "    cleaned_input = user_input.strip().lower()\n",
    "    \n",
    "    # Trace just the LLM call using context manager\n",
    "    with trace_llm_call(model=\"gpt-4\", provider=\"openai\", operation=\"query_processing\") as span:\n",
    "        print(\"ğŸ¤– Making LLM call within context manager...\")\n",
    "        time.sleep(0.4)\n",
    "        \n",
    "        # Mock LLM response\n",
    "        response = f\"Processed response for: {cleaned_input[:30]}...\"\n",
    "        \n",
    "        # Add custom attributes to the span\n",
    "        span.set_attributes({\n",
    "            \"llm.input_length\": len(cleaned_input),\n",
    "            \"llm.output_length\": len(response),\n",
    "            \"llm.processing_type\": \"query_understanding\"\n",
    "        })\n",
    "        \n",
    "        print(f\"âœ… LLM response generated: {len(response)} characters\")\n",
    "    \n",
    "    # Post-processing (not traced)\n",
    "    final_response = f\"Final: {response}\"\n",
    "    print(f\"ğŸ“¤ Final response: {final_response[:50]}...\")\n",
    "    \n",
    "    return final_response\n",
    "\n",
    "# Agent operation context manager\n",
    "def agent_task_with_context_manager(task: str) -> Dict[str, Any]:\n",
    "    \"\"\"Demonstrate agent operation tracing with context manager.\"\"\"\n",
    "    print(f\"ğŸ¤– Agent Task: '{task}'\")\n",
    "    \n",
    "    with trace_agent_operation(\n",
    "        agent_type=\"task_agent\", \n",
    "        operation=\"task_execution\",\n",
    "        capabilities=[\"task_planning\", \"execution\", \"monitoring\"]\n",
    "    ) as span:\n",
    "        print(\"âš™ï¸  Executing agent task...\")\n",
    "        time.sleep(0.3)\n",
    "        \n",
    "        # Mock agent work\n",
    "        result = {\n",
    "            \"task\": task,\n",
    "            \"status\": \"completed\",\n",
    "            \"steps_executed\": 5,\n",
    "            \"success_rate\": 0.95\n",
    "        }\n",
    "        \n",
    "        # Add agent-specific attributes\n",
    "        span.set_attributes({\n",
    "            \"agent.task_complexity\": \"medium\",\n",
    "            \"agent.steps_executed\": result[\"steps_executed\"],\n",
    "            \"agent.success_rate\": result[\"success_rate\"]\n",
    "        })\n",
    "        \n",
    "        print(f\"âœ… Agent task completed with {result['success_rate']:.1%} success rate\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Generic operation context manager\n",
    "def complex_operation_with_tracing() -> Dict[str, Any]:\n",
    "    \"\"\"Demonstrate generic operation tracing.\"\"\"\n",
    "    print(\"ğŸ”§ Starting complex operation...\")\n",
    "    \n",
    "    with trace_operation(operation_name=\"complex_data_processing\") as span:\n",
    "        # Step 1: Data loading\n",
    "        print(\"ğŸ“¥ Step 1: Loading data...\")\n",
    "        time.sleep(0.2)\n",
    "        span.set_attributes({\"step\": \"data_loading\", \"records_loaded\": 1000})\n",
    "        \n",
    "        # Step 2: Processing\n",
    "        print(\"âš™ï¸  Step 2: Processing data...\")\n",
    "        time.sleep(0.3)\n",
    "        span.set_attributes({\"step\": \"processing\", \"records_processed\": 950})\n",
    "        \n",
    "        # Step 3: Output\n",
    "        print(\"ğŸ“¤ Step 3: Generating output...\")\n",
    "        time.sleep(0.1)\n",
    "        span.set_attributes({\"step\": \"output\", \"records_output\": 950})\n",
    "        \n",
    "        result = {\n",
    "            \"operation\": \"complex_data_processing\",\n",
    "            \"input_records\": 1000,\n",
    "            \"processed_records\": 950,\n",
    "            \"success\": True\n",
    "        }\n",
    "        \n",
    "        print(\"âœ… Complex operation completed successfully\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Streaming LLM Examples\n",
    "\n",
    "class MockStreamChunk:\n",
    "    \"\"\"Mock streaming response chunk.\"\"\"\n",
    "    def __init__(self, content: str):\n",
    "        self.choices = [MockChoice(content)]\n",
    "\n",
    "class MockChoice:\n",
    "    \"\"\"Mock choice in streaming response.\"\"\"\n",
    "    def __init__(self, content: str):\n",
    "        self.delta = MockDelta(content)\n",
    "\n",
    "class MockDelta:\n",
    "    \"\"\"Mock delta content.\"\"\"\n",
    "    def __init__(self, content: str):\n",
    "        self.content = content\n",
    "\n",
    "def mock_streaming_response(prompt: str) -> Iterator[MockStreamChunk]:\n",
    "    \"\"\"Generate mock streaming response.\"\"\"\n",
    "    words = f\"This is a streaming response to: {prompt}. Each word comes separately.\".split()\n",
    "    for word in words:\n",
    "        time.sleep(0.05)  # Simulate streaming delay\n",
    "        yield MockStreamChunk(word + \" \")\n",
    "\n",
    "def test_streaming_with_context_manager(prompt: str) -> str:\n",
    "    \"\"\"Test streaming LLM with context manager.\"\"\"\n",
    "    print(f\"ğŸŒŠ Streaming LLM call: '{prompt[:30]}...'\")\n",
    "    \n",
    "    # Create mock stream\n",
    "    stream = mock_streaming_response(prompt)\n",
    "    \n",
    "    # Use streaming context manager\n",
    "    with streaming_llm(model=\"gpt-4\", provider=\"openai\", operation=\"streaming_chat\") as stream_manager:\n",
    "        print(\"ğŸ“º Streaming response: \", end=\"\")\n",
    "        full_response = \"\"\n",
    "        \n",
    "        for chunk in stream:\n",
    "            token = chunk.choices[0].delta.content\n",
    "            if token:\n",
    "                # Add token to stream manager for tracing\n",
    "                stream_manager.add_token(token)\n",
    "                print(token, end=\"\")\n",
    "                full_response += token\n",
    "        \n",
    "        # Add final metadata\n",
    "        stream_manager.add_metadata({\n",
    "            \"streaming.final_length\": len(full_response),\n",
    "            \"streaming.total_chunks\": len(full_response.split())\n",
    "        })\n",
    "        \n",
    "        print(f\"\\\\nâœ… Streaming completed: {len(full_response)} characters\")\n",
    "    \n",
    "    return full_response.strip()\n",
    "\n",
    "# Thread Context for Conversation Tracking\n",
    "\n",
    "def test_thread_context_conversation() -> None:\n",
    "    \"\"\"Test conversation thread tracking.\"\"\"\n",
    "    print(\"ğŸ’¬ Testing Thread Context for Conversations...\")\n",
    "    \n",
    "    with ThreadContext(name=\"demo_conversation\", metadata={\"session\": \"demo\"}) as thread:\n",
    "        # Simulate conversation turns\n",
    "        \n",
    "        # Turn 1\n",
    "        thread.add_message(\"user\", \"Hello, can you help me with AI observability?\")\n",
    "        print(\"ğŸ‘¤ User: Hello, can you help me with AI observability?\")\n",
    "        \n",
    "        # Simulate LLM response within thread\n",
    "        with trace_llm_call(model=\"gpt-4\") as llm_span:\n",
    "            time.sleep(0.3)\n",
    "            response1 = \"I'd be happy to help you with AI observability!\"\n",
    "            thread.add_message(\"assistant\", response1)\n",
    "            print(f\"ğŸ¤– Assistant: {response1}\")\n",
    "        \n",
    "        # Turn 2  \n",
    "        thread.add_message(\"user\", \"What are the key components?\")\n",
    "        print(\"ğŸ‘¤ User: What are the key components?\")\n",
    "        \n",
    "        with trace_llm_call(model=\"gpt-4\") as llm_span:\n",
    "            time.sleep(0.4)\n",
    "            response2 = \"Key components include tracing, metrics, and logging.\"\n",
    "            thread.add_message(\"assistant\", response2)\n",
    "            print(f\"ğŸ¤– Assistant: {response2}\")\n",
    "        \n",
    "        # Get thread statistics\n",
    "        stats = thread.get_statistics()\n",
    "        print(f\"\\\\nğŸ“Š Thread Stats: {stats['message_count']} messages, {stats['turn_count']} turns\")\n",
    "\n",
    "# Test all context manager and streaming features\n",
    "print(\"ğŸ”„ Testing Context Managers and Streaming...\")\n",
    "\n",
    "# Test context managers\n",
    "print(\"\\\\n1ï¸âƒ£ Context Manager Examples:\")\n",
    "query_result = process_user_query_with_context_managers(\"What are the benefits of AI observability?\")\n",
    "\n",
    "agent_result = agent_task_with_context_manager(\"Analyze system performance metrics\")\n",
    "\n",
    "operation_result = complex_operation_with_tracing()\n",
    "\n",
    "# Test streaming\n",
    "print(\"\\\\n2ï¸âƒ£ Streaming Examples:\")\n",
    "stream_result = test_streaming_with_context_manager(\"Explain machine learning concepts\")\n",
    "\n",
    "# Test thread context\n",
    "print(\"\\\\n3ï¸âƒ£ Thread Context Examples:\")\n",
    "test_thread_context_conversation()\n",
    "\n",
    "print(\"\\\\nâœ… Context managers and streaming testing completed!\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## âœ… FIXED: Correct trace_operation Usage\n",
    "\n",
    "The `trace_operation()` context manager has been fixed with the correct syntax:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORRECTED trace_operation Examples\n",
    "# The correct syntax is: trace_operation(operation_name, attributes=dict, tags=dict)\n",
    "\n",
    "def test_correct_trace_operation_usage():\n",
    "    \"\"\"Demonstrate the CORRECT syntax for trace_operation context manager.\"\"\"\n",
    "    print(\"ğŸ”§ Testing CORRECT trace_operation usage...\")\n",
    "    \n",
    "    # âœ… CORRECT: First parameter is operation_name (string), second is attributes (dict)\n",
    "    with trace_operation(\"data_processing_pipeline\", \n",
    "                        attributes={\"operation_type\": \"data_pipeline\", \"complexity\": \"high\"}) as span:\n",
    "        # Step 1: Data loading\n",
    "        print(\"ğŸ“¥ Step 1: Loading data...\")\n",
    "        time.sleep(0.2)\n",
    "        span.set_attributes({\"step\": \"data_loading\", \"records_loaded\": 1000})\n",
    "        \n",
    "        # Step 2: Processing\n",
    "        print(\"âš™ï¸  Step 2: Processing data...\")\n",
    "        time.sleep(0.3)\n",
    "        span.set_attributes({\"step\": \"processing\", \"records_processed\": 950})\n",
    "        \n",
    "        # Step 3: Output\n",
    "        print(\"ğŸ“¤ Step 3: Generating output...\")\n",
    "        time.sleep(0.1)\n",
    "        span.set_attributes({\"step\": \"output\", \"records_output\": 950})\n",
    "        \n",
    "        result = {\n",
    "            \"operation\": \"data_processing_pipeline\",\n",
    "            \"input_records\": 1000,\n",
    "            \"processed_records\": 950,\n",
    "            \"success\": True\n",
    "        }\n",
    "        \n",
    "        print(\"âœ… Complex operation completed successfully\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "def test_correct_batch_operations():\n",
    "    \"\"\"Demonstrate correct trace_operation usage in batch processing.\"\"\"\n",
    "    print(\"ğŸ“¦ Testing CORRECT batch trace_operation usage...\")\n",
    "    \n",
    "    operations = []\n",
    "    \n",
    "    for i in range(3):  # Reduced to 3 for demo\n",
    "        # âœ… CORRECT: operation_name first, then attributes dict\n",
    "        with trace_operation(f\"batch_operation_{i}\", \n",
    "                           attributes={\"operation_type\": \"batch_demo\", \"batch_index\": i}) as span:\n",
    "            span.set_attributes({\n",
    "                \"batch.operation_number\": i,\n",
    "                \"batch.total_operations\": 3,\n",
    "                \"operation.size\": \"small\"\n",
    "            })\n",
    "            time.sleep(0.1)  # Quick operations\n",
    "            operations.append(f\"operation_{i}\")\n",
    "            print(f\"ğŸ”¸ Batch operation {i+1}/3 completed\")\n",
    "    \n",
    "    print(f\"âœ… Batch processing completed: {len(operations)} operations\")\n",
    "    return operations\n",
    "\n",
    "# Test the corrected functions\n",
    "print(\"ğŸ”§ Testing CORRECTED Context Manager Usage...\")\n",
    "\n",
    "print(\"\\\\n1ï¸âƒ£ Correct trace_operation Usage:\")\n",
    "operation_result = test_correct_trace_operation_usage()\n",
    "\n",
    "print(\"\\\\n2ï¸âƒ£ Correct Batch Operations:\")\n",
    "batch_result = test_correct_batch_operations()\n",
    "\n",
    "print(f\"\\\\nâœ… All corrected context manager examples completed!\")\n",
    "print(f\"Operation result: {operation_result['success']}\")\n",
    "print(f\"Batch operations: {len(batch_result)} completed\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## âœ… FIXED: Correct create_traced_agent Usage\n",
    "\n",
    "The `create_traced_agent()` function has been fixed with the correct parameters:\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## ğŸ”„ FINAL COMPREHENSIVE FLUSH\n",
    "\n",
    "Final flush to ensure all traces from the entire demo are sent to your endpoint.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## ğŸ”§ FIXED: Enhanced SDK Initialization with Endpoint Debugging\n",
    "\n",
    "The endpoint configuration has been fixed with proper debugging and transport settings:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”§ ENHANCED SDK INITIALIZATION WITH ENDPOINT DEBUGGING\n",
    "import noveum_trace\n",
    "from noveum_trace import trace, trace_agent, trace_llm, trace_tool\n",
    "import logging\n",
    "import sys\n",
    "import requests\n",
    "\n",
    "# ğŸ” COMPREHENSIVE DEBUGGING SETUP\n",
    "print(\"ğŸ”§ Setting up enhanced debugging for transport layer...\")\n",
    "\n",
    "# Set up comprehensive logging with detailed output\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG, \n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[logging.StreamHandler(sys.stdout)]\n",
    ")\n",
    "\n",
    "# Enable specific loggers for transport debugging\n",
    "loggers_to_enable = [\n",
    "    'noveum_trace.transport', \n",
    "    'noveum_trace.transport.http_transport',\n",
    "    'urllib3.connectionpool'\n",
    "]\n",
    "\n",
    "for logger_name in loggers_to_enable:\n",
    "    logger = logging.getLogger(logger_name)\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "\n",
    "print(\"âœ… Enhanced debugging enabled\")\n",
    "\n",
    "# ğŸŒ ENDPOINT VERIFICATION \n",
    "def verify_endpoint():\n",
    "    \\\"\\\"\\\"Verify that the Beeceptor endpoint is reachable.\\\"\\\"\\\"\n",
    "    endpoint = \"https://noveum-trace.free.beeceptor.com\"\n",
    "    \n",
    "    print(f\"ğŸ” Verifying endpoint reachability: {endpoint}\")\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(endpoint, timeout=10)\n",
    "        print(f\"âœ… Base endpoint reachable - Status: {response.status_code}\")\n",
    "        \n",
    "        # Test the actual trace endpoints\n",
    "        trace_endpoints = [\n",
    "            f\"{endpoint}/v1/trace\",   # Single trace endpoint\n",
    "            f\"{endpoint}/v1/traces\"   # Batch trace endpoint  \n",
    "        ]\n",
    "        \n",
    "        for test_endpoint in trace_endpoints:\n",
    "            try:\n",
    "                test_response = requests.head(test_endpoint, timeout=5)\n",
    "                print(f\"ğŸ“¡ {test_endpoint} - Status: {test_response.status_code}\")\n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸  {test_endpoint} - Error: {e}\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Endpoint verification failed: {e}\")\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Verify endpoint first\n",
    "endpoint_ok = verify_endpoint()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸš€ ENHANCED SDK INITIALIZATION\n",
    "try:\n",
    "    print(\"\\\\nğŸš€ Initializing Noveum Trace SDK with enhanced configuration...\")\n",
    "    \n",
    "    # ğŸ“‹ Display endpoint mapping\n",
    "    base_endpoint = \"https://api.noveum.ai/api\"\n",
    "    print(f\"ğŸŒ Base Endpoint: {base_endpoint}\")\n",
    "    print(f\"ğŸ“¡ Single Trace Endpoint: {base_endpoint}/v1/trace\")\n",
    "    print(f\"ğŸ“¦ Batch Trace Endpoint: {base_endpoint}/v1/traces\")\n",
    "    print(f\"ğŸ”§ Transport Mode: Individual traces (batch_size=1) for better debugging\")\n",
    "    \n",
    "    noveum_trace.init(\n",
    "        api_key=os.getenv('NOVEUM_API_KEY'),\n",
    "        project=\"jupyter-test-project\",\n",
    "        environment=\"development\", \n",
    "        endpoint=base_endpoint,  # SDK will append /v1/trace or /v1/traces automatically\n",
    "        debug=True,  # Enable debug mode\n",
    "        \n",
    "        # ğŸ”§ Enhanced transport configuration for debugging\n",
    "        transport_config={\n",
    "            \"timeout\": 30,           # 30 second timeout (generous for debugging)\n",
    "            \"retry_attempts\": 0,     # No retries for faster debugging feedback  \n",
    "            \"batch_size\": 1,         # Send traces individually (not batched)\n",
    "            \"batch_timeout\": 0.5,    # Send traces immediately\n",
    "            \"compression\": False,    # No compression for easier debugging\n",
    "            \"verify_ssl\": True       # Verify SSL certificates\n",
    "        },\n",
    "        \n",
    "        # âœ… Comprehensive tracing configuration  \n",
    "        tracing_config={\n",
    "            \"sample_rate\": 1.0,        # Trace 100% of operations\n",
    "            \"capture_errors\": True,    # Capture error details\n",
    "            \"auto_flush\": True         # Automatically flush traces\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    print(\"âœ… Noveum Trace SDK initialized successfully!\")\n",
    "    \n",
    "    # ğŸ“Š Display configuration details\n",
    "    config = noveum_trace.get_config()\n",
    "    print(f\"ğŸ“Š Project: {config.project}\")\n",
    "    print(f\"ğŸ”§ Environment: {config.environment}\")\n",
    "    print(f\"ğŸŒ Transport Endpoint: {config.transport.endpoint}\")\n",
    "    print(f\"ğŸ“¦ Batch Size: {config.transport.batch_size}\")\n",
    "    print(f\"â±ï¸  Batch Timeout: {config.transport.batch_timeout}s\")\n",
    "    print(f\"ğŸ” Debug Mode: {config.debug}\")\n",
    "    \n",
    "    print(\"\\\\nğŸ¯ SDK initialization completed!\")\n",
    "    print(\"ğŸ“‹ Check the debug log output above for HTTP request details\")\n",
    "    print(\"ğŸŒ Your traces should now be visible at: \" + base_endpoint)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error initializing SDK: {e}\")\n",
    "    print(\"Continuing with demo - traces will be logged locally\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## ğŸ”§ Debug: Testing Endpoint Connectivity\n",
    "\n",
    "Let's test if traces are being sent to your configured endpoint and diagnose any issues.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 6: Multi-Agent System\n",
    "\n",
    "Test multi-agent workflow tracing with the `@trace_agent` decorator.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@trace_agent(agent_id=\"research_agent\")\n",
    "def research_agent(query: str) -> Dict[str, Any]:\n",
    "    \"\"\"Research agent that gathers information.\"\"\"\n",
    "    print(f\"ğŸ” Research Agent: Processing query '{query}'\")\n",
    "\n",
    "    # Simulate research process\n",
    "    time.sleep(0.4)\n",
    "\n",
    "    # Mock research findings\n",
    "    findings = {\n",
    "        \"query\": query,\n",
    "        \"sources\": [\"source1.pdf\", \"source2.html\", \"source3.json\"],\n",
    "        \"key_points\": [\n",
    "            \"Point 1: Observability improves system reliability\",\n",
    "            \"Point 2: Tracing helps identify bottlenecks\",\n",
    "            \"Point 3: Monitoring enables proactive maintenance\"\n",
    "        ],\n",
    "        \"confidence\": 0.87,\n",
    "        \"research_time\": \"0.4s\"\n",
    "    }\n",
    "\n",
    "    print(f\"âœ… Research completed with {len(findings['sources'])} sources\")\n",
    "    return findings\n",
    "\n",
    "@trace_agent(agent_id=\"orchestrator\")\n",
    "def orchestrate_workflow(task: str) -> Dict[str, Any]:\n",
    "    \"\"\"Orchestrator agent that coordinates multiple agents.\"\"\"\n",
    "    print(f\"ğŸ­ Orchestrator: Starting workflow for task '{task}'\")\n",
    "\n",
    "    # Step 1: Research\n",
    "    print(\"\\nğŸ” Step 1: Research Phase\")\n",
    "    research_data = research_agent(task)\n",
    "\n",
    "    # Step 2: Analysis (simplified)\n",
    "    print(\"\\nğŸ“Š Step 2: Analysis Phase\")\n",
    "    analysis_data = {\n",
    "        \"insights\": [\"Observability is crucial\", \"Tracing provides insights\"],\n",
    "        \"quality_score\": 0.89\n",
    "    }\n",
    "\n",
    "    # Final orchestration result\n",
    "    workflow_result = {\n",
    "        \"task\": task,\n",
    "        \"workflow_id\": \"wf-001\",\n",
    "        \"phases_completed\": 2,\n",
    "        \"research_summary\": research_data[\"key_points\"],\n",
    "        \"analysis_summary\": analysis_data[\"insights\"],\n",
    "        \"overall_confidence\": research_data[\"confidence\"],\n",
    "        \"total_time\": \"1.0s\"\n",
    "    }\n",
    "\n",
    "    print(\"\\nâœ… Orchestrator: Workflow completed successfully\")\n",
    "    return workflow_result\n",
    "\n",
    "# Test the multi-agent workflow\n",
    "task = \"Analyze the importance of observability in AI systems\"\n",
    "workflow_result = orchestrate_workflow(task)\n",
    "print(\"\\nğŸ­ Final Workflow Result:\")\n",
    "print(f\"Task: {workflow_result['task']}\")\n",
    "print(f\"Confidence: {workflow_result['overall_confidence']:.2f}\")\n",
    "print(f\"Phases: {workflow_result['phases_completed']}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 7: Tool Tracing\n",
    "\n",
    "Test tool tracing with the `@trace_tool` decorator.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@trace_tool(tool_name=\"calculator\")\n",
    "def calculate(operation: str, a: float, b: float) -> Dict[str, Any]:\n",
    "    \"\"\"A calculator tool with tracing.\"\"\"\n",
    "    print(f\"ğŸ”¢ Calculator: Performing {operation} on {a} and {b}\")\n",
    "\n",
    "    operations = {\n",
    "        \"add\": lambda x, y: x + y,\n",
    "        \"subtract\": lambda x, y: x - y,\n",
    "        \"multiply\": lambda x, y: x * y,\n",
    "        \"divide\": lambda x, y: x / y if y != 0 else None\n",
    "    }\n",
    "\n",
    "    if operation not in operations:\n",
    "        return {\"error\": f\"Unknown operation: {operation}\"}\n",
    "\n",
    "    try:\n",
    "        result = operations[operation](a, b)\n",
    "        if result is None:\n",
    "            return {\"error\": \"Division by zero\"}\n",
    "\n",
    "        return {\n",
    "            \"operation\": operation,\n",
    "            \"operands\": [a, b],\n",
    "            \"result\": result,\n",
    "            \"success\": True\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e), \"success\": False}\n",
    "\n",
    "@trace_tool(tool_name=\"text_analyzer\")\n",
    "def analyze_text(text: str) -> Dict[str, Any]:\n",
    "    \"\"\"Text analysis tool with tracing.\"\"\"\n",
    "    print(f\"ğŸ“ Text Analyzer: Analyzing text of length {len(text)}\")\n",
    "\n",
    "    # Simulate analysis\n",
    "    time.sleep(0.2)\n",
    "\n",
    "    analysis = {\n",
    "        \"text_length\": len(text),\n",
    "        \"word_count\": len(text.split()),\n",
    "        \"sentence_count\": text.count('.') + text.count('!') + text.count('?'),\n",
    "        \"avg_word_length\": sum(len(word) for word in text.split()) / len(text.split()) if text.split() else 0\n",
    "    }\n",
    "\n",
    "    print(f\"âœ… Analysis complete: {analysis['word_count']} words, {analysis['sentence_count']} sentences\")\n",
    "    return analysis\n",
    "\n",
    "# Test tool tracing\n",
    "calc_result = calculate(\"multiply\", 15, 4)\n",
    "print(f\"\\nğŸ”¢ Calculator Result: {calc_result}\")\n",
    "\n",
    "text_to_analyze = \"This is a sample text for testing the noveum-trace SDK. It contains multiple sentences!\"\n",
    "text_analysis = analyze_text(text_to_analyze)\n",
    "print(f\"\\nğŸ“ Text Analysis Result: {text_analysis}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 8: Summary and Cleanup\n",
    "\n",
    "Test summary and cleanup of resources.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pkg_resources\n",
    "\n",
    "# Test summary\n",
    "def print_test_summary():\n",
    "    \"\"\"Print a summary of all tests performed.\"\"\"\n",
    "    print(\"ğŸ“‹ NOVEUM TRACE SDK TEST SUMMARY\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # Check SDK version\n",
    "    try:\n",
    "        version = pkg_resources.get_distribution(\"noveum-trace\").version\n",
    "        print(f\"âœ… SDK Version: {version}\")\n",
    "    except:\n",
    "        print(\"âš ï¸  Could not determine SDK version\")\n",
    "\n",
    "    # Environment check\n",
    "    print(f\"âœ… Python Version: {sys.version.split()[0]}\")\n",
    "    print(f\"âœ… Environment Variables: {'âœ“' if os.getenv('NOVEUM_API_KEY') else 'âœ—'}\")\n",
    "\n",
    "    # Features tested\n",
    "    features_tested = [\n",
    "        \"Basic function tracing (@trace)\",\n",
    "        \"LLM call tracing (@trace_llm)\",\n",
    "        \"Agent workflow tracing (@trace_agent)\",\n",
    "        \"Tool tracing (@trace_tool)\",\n",
    "        \"Multi-agent orchestration\",\n",
    "        \"Error handling\",\n",
    "        \"Framework integration simulation\"\n",
    "    ]\n",
    "\n",
    "    print(\"\\nğŸ§ª Features Tested:\")\n",
    "    for feature in features_tested:\n",
    "        print(f\"  âœ… {feature}\")\n",
    "\n",
    "    print(\"\\nğŸ¯ Key Results:\")\n",
    "    print(\"  ğŸ”§ All decorators: Functional\")\n",
    "    print(\"  ğŸ¤– Multi-agent support: Functional\")\n",
    "    print(\"  ğŸ”Œ Framework integration: Simulated successfully\")\n",
    "\n",
    "    print(\"\\nâœ… All tests completed successfully!\")\n",
    "    print(\"\\nğŸ“– Next Steps:\")\n",
    "    print(\"  1. Set up your actual NOVEUM_API_KEY for production use\")\n",
    "    print(\"  2. Integrate with your LLM applications\")\n",
    "    print(\"  3. Set up dashboards and monitoring\")\n",
    "    print(\"  4. Configure alerting based on trace data\")\n",
    "\n",
    "# Clean up function\n",
    "def cleanup_resources():\n",
    "    \"\"\"Clean up any resources created during testing.\"\"\"\n",
    "    print(\"ğŸ§¹ Cleaning up test resources...\")\n",
    "\n",
    "    try:\n",
    "        # Attempt to flush any pending traces\n",
    "        noveum_trace.flush()\n",
    "        print(\"âœ… Traces flushed successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"â„¹ï¸  Trace flush: {e}\")\n",
    "\n",
    "    print(\"âœ… Cleanup completed\")\n",
    "\n",
    "# Run summary and cleanup\n",
    "print_test_summary()\n",
    "cleanup_resources()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## ğŸ‰ Congratulations!\n",
    "\n",
    "You have successfully tested the Noveum Trace SDK from PyPI! \n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "- âœ… Installation from PyPI\n",
    "- âœ… Environment setup with proper API keys\n",
    "- âœ… Basic function tracing with `@trace`\n",
    "- âœ… LLM call tracing with `@trace_llm`\n",
    "- âœ… Agent workflow tracing with `@trace_agent`\n",
    "- âœ… Tool tracing with `@trace_tool`\n",
    "- âœ… Multi-agent system orchestration\n",
    "- âœ… Error handling and edge cases\n",
    "- âœ… Performance considerations\n",
    "- âœ… Framework integration patterns\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. **Production Setup**: Replace the dummy API key with your actual Noveum API key\n",
    "2. **Integration**: Integrate these patterns into your existing LLM applications\n",
    "3. **Monitoring**: Set up dashboards to monitor your traced applications\n",
    "4. **Optimization**: Use the trace data to optimize your application performance\n",
    "\n",
    "### Resources:\n",
    "\n",
    "- ğŸ“š [Noveum Trace Documentation](https://docs.noveum.ai)\n",
    "- ğŸ™ [GitHub Repository](https://github.com/Noveum/noveum-trace)\n",
    "- ğŸ“¦ [PyPI Package](https://pypi.org/project/noveum-trace/)\n",
    "\n",
    "Happy tracing! ğŸš€\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
