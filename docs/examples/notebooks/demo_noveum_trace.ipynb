{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Noveum Trace SDK Testing Notebook\n",
    "\n",
    "This notebook demonstrates the complete functionality of the Noveum Trace SDK installed from PyPI.\n",
    "\n",
    "## Features Tested:\n",
    "- Basic installation and setup\n",
    "- Environment variable configuration\n",
    "- Function tracing with decorators\n",
    "- LLM call tracing\n",
    "- Agent workflow tracing\n",
    "- Multi-agent systems\n",
    "- Tool tracing\n",
    "- Context managers\n",
    "- Streaming support\n",
    "- Integration examples\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 1: Install Required Dependencies\n",
    "\n",
    "First, we'll install noveum-trace from PyPI along with some additional dependencies for testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install noveum-trace from PyPI and testing dependencies\n",
    "%pip install noveum-trace python-dotenv openai anthropic\n",
    "%pip install --upgrade noveum-trace pip\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 2: Set Up Environment Variables\n",
    "\n",
    "Configure the necessary environment variables for the SDK to work properly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file if it exists\n",
    "# Note: Using robust path detection since __file__ is not available in Jupyter notebooks\n",
    "try:\n",
    "    # Try to get current working directory\n",
    "    current_dir = os.getcwd()\n",
    "    print(f\"üìÅ Current directory: {current_dir}\")\n",
    "    \n",
    "    # Look for .env file in current directory and parent directories\n",
    "    env_file_found = False\n",
    "    search_dir = current_dir\n",
    "    \n",
    "    for _ in range(5):  # Search up to 5 levels up\n",
    "        env_file = os.path.join(search_dir, '.env')\n",
    "        if os.path.exists(env_file):\n",
    "            print(f\"üìÑ Found .env file: {env_file}\")\n",
    "            load_dotenv(env_file)\n",
    "            env_file_found = True\n",
    "            break\n",
    "        search_dir = os.path.dirname(search_dir)\n",
    "        if search_dir == os.path.dirname(search_dir):  # Reached root\n",
    "            break\n",
    "    \n",
    "    if not env_file_found:\n",
    "        print(\"‚ÑπÔ∏è  No .env file found - continuing without it\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Error loading .env file: {e}\")\n",
    "    print(\"‚ÑπÔ∏è  Continuing without .env file\")\n",
    "\n",
    "# Set up environment variables for testing\n",
    "# Replace with your actual API key or set in .env file\n",
    "if not os.getenv('NOVEUM_API_KEY'):\n",
    "    # For testing purposes, you can set a dummy API key\n",
    "    # In production, use your actual Noveum API key\n",
    "    os.environ['NOVEUM_API_KEY'] = 'noveum_API_KEY'\n",
    "    print(\"‚ö†Ô∏è  Using dummy API key for testing. Set NOVEUM_API_KEY environment variable for production use.\")\n",
    "else:\n",
    "    print(\"‚úÖ NOVEUM_API_KEY found i\")\n",
    "\n",
    "# Optional: Set OpenAI API key for LLM examples\n",
    "if not os.getenv('OPENAI_API_KEY'):\n",
    "    print(\"‚ÑπÔ∏è  OPENAI_API_KEY not found. LLM examples will use mock responses.\")\n",
    "else:\n",
    "    print(\"‚úÖ OPENAI_API_KEY found in environment\")\n",
    "\n",
    "print(\"\\nüìã Environment Variables Status:\")\n",
    "print(f\"NOVEUM_API_KEY: {'‚úì' if os.getenv('NOVEUM_API_KEY') else '‚úó'}\")\n",
    "print(f\"OPENAI_API_KEY: {'‚úì' if os.getenv('OPENAI_API_KEY') else '‚úó'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## üîÑ FLUSH HELPER: Automatic Trace Sending\n",
    "\n",
    "To ensure all traces are sent immediately to your endpoint, we'll create a helper function that can be called after any traced operation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîÑ FLUSH HELPER FUNCTIONS FOR IMMEDIATE TRACE SENDING\n",
    "\n",
    "def flush_traces(operation_name=\"Operation\"):\n",
    "    \"\"\"\n",
    "    Helper function to flush traces immediately to endpoint.\n",
    "    Call this after any traced operation to ensure traces are sent right away.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        noveum_trace.flush()\n",
    "        print(f\"üì§ ‚úÖ {operation_name} traces flushed successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"üì§ ‚ö†Ô∏è  {operation_name} flush warning: {e}\")\n",
    "\n",
    "def auto_flush_decorator(func):\n",
    "    \"\"\"\n",
    "    Decorator that automatically flushes traces after function execution.\n",
    "    Use this for any function that contains traced operations.\n",
    "    \"\"\"\n",
    "    def wrapper(*args, **kwargs):\n",
    "        result = func(*args, **kwargs)\n",
    "        flush_traces(func.__name__)\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "# Test the flush helper\n",
    "print(\"üîß Flush helper functions initialized\")\n",
    "print(\"üìã Usage:\")\n",
    "print(\"  - Call flush_traces('operation_name') after any traced operation\")\n",
    "print(\"  - Use @auto_flush_decorator on functions containing traced operations\")\n",
    "print(\"  - This ensures immediate trace sending to your endpoint\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 3: Initialize the SDK\n",
    "\n",
    "Initialize the Noveum Trace SDK with your project configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import noveum_trace\n",
    "from noveum_trace import trace, trace_agent, trace_llm, trace_tool\n",
    "import logging\n",
    "\n",
    "# Enable detailed logging to debug transport issues\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "transport_logger = logging.getLogger('noveum_trace.transport')\n",
    "transport_logger.setLevel(logging.DEBUG)\n",
    "ENDPOINT = \"https://api.noveum.ai/api\"\n",
    "\n",
    "# Initialize the SDK with proper endpoint configuration\n",
    "try:\n",
    "    # IMPORTANT: The SDK will append \"/v1/traces\" to your endpoint\n",
    "    # So \"https://noveum-trace.free.beeceptor.com\" becomes \"https://noveum-trace.free.beeceptor.com/v1/traces\"\n",
    "    noveum_trace.init(\n",
    "        api_key=os.getenv('NOVEUM_API_KEY'),\n",
    "        project=\"jupyter-test-project\", \n",
    "        environment=\"development\",\n",
    "        endpoint=ENDPOINT,  # SDK will add /v1/traces automatically\n",
    "        debug=True,  # Enable debug mode for testing\n",
    "        \n",
    "        # Transport configuration for better reliability\n",
    "        transport_config={\n",
    "            \"timeout\": 10,           # 10 second timeout\n",
    "            \"retry_attempts\": 2,     # Retry failed requests 2 times\n",
    "            \"batch_size\": 10,        # Smaller batches for demo\n",
    "            \"batch_timeout\": 2.0,    # Send batches every 2 seconds\n",
    "            \"compression\": False     # Disable compression for debugging\n",
    "        },\n",
    "        \n",
    "        # Tracing configuration\n",
    "        tracing_config={\n",
    "            \"sample_rate\": 1.0,      # Trace 100% of operations\n",
    "            \"capture_errors\": True,\n",
    "            \"capture_stack_traces\": True\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Noveum Trace SDK initialized successfully!\")\n",
    "    print(\"üìä Project: jupyter-test-project\")\n",
    "    print(\"üîß Environment: development\") \n",
    "    print(f\"üåê Endpoint: {ENDPOINT}/v1/traces (auto-appended)\")\n",
    "    print(\"üîç Debug logging enabled - check console for HTTP request details\")\n",
    "    \n",
    "    # Get the current configuration to verify settings\n",
    "    config = noveum_trace.get_config()\n",
    "    print(f\"üìã Config verified - Endpoint: {config.transport.endpoint}\")\n",
    "    print(f\"üì¶ Batch size: {config.transport.batch_size}\")\n",
    "    print(f\"‚è±Ô∏è  Batch timeout: {config.transport.batch_timeout}s\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error initializing SDK: {e}\")\n",
    "    print(\"Continuing with demo - traces will be logged locally\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 5: LLM Call Tracing\n",
    "\n",
    "Test LLM call tracing with the `@trace_llm` decorator.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîÑ FLUSH AFTER LLM CALL TRACING\n",
    "# This ensures the @trace_llm decorator traces are sent immediately\n",
    "\n",
    "flush_traces(\"LLM Call Tracing (call_language_model)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mock LLM responses for testing (replace with actual API calls if you have keys)\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "from noveum_trace import trace_llm\n",
    "\n",
    "def mock_openai_call(prompt: str, model: str = \"gpt-4\") -> str:\n",
    "    \"\"\"Mock OpenAI API call for testing.\"\"\"\n",
    "    responses = [\n",
    "        \"This is a mock response from the language model.\",\n",
    "        \"Here's a simulated AI response for testing purposes.\",\n",
    "        \"Mock LLM output to demonstrate tracing functionality.\"\n",
    "    ]\n",
    "    time.sleep(0.3)  # Simulate API call latency\n",
    "    return random.choice(responses)\n",
    "\n",
    "@trace_llm\n",
    "def call_language_model(prompt: str, model: str = \"gpt-4\") -> str:\n",
    "    \"\"\"Call a language model with tracing.\"\"\"\n",
    "    print(f\"ü§ñ Calling {model} with prompt: {prompt[:50]}...\")\n",
    "\n",
    "    # Use real OpenAI API if available, otherwise use mock\n",
    "    if os.getenv('OPENAI_API_KEY'):\n",
    "        try:\n",
    "            import openai\n",
    "            client = openai.OpenAI()\n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                max_tokens=100\n",
    "            )\n",
    "            return response.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  OpenAI API call failed: {e}. Using mock response.\")\n",
    "            return mock_openai_call(prompt, model)\n",
    "    else:\n",
    "        print(\"üìù Using mock LLM response (no API key provided)\")\n",
    "        return mock_openai_call(prompt, model)\n",
    "\n",
    "# Test LLM tracing\n",
    "prompt = \"Explain the benefits of observability in AI systems.\"\n",
    "response = call_language_model(prompt)\n",
    "print(f\"\\nüéØ LLM Response: {response}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîÑ FLUSH AFTER ENHANCED LLM TRACING\n",
    "# This ensures all enhanced LLM traces (Anthropic, OpenAI, Google) are sent immediately\n",
    "\n",
    "flush_traces(\"Enhanced LLM Tracing (Anthropic + OpenAI + Google)\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 5.1: Enhanced LLM Tracing Examples\n",
    "\n",
    "Demonstrate various LLM tracing features including different providers, metadata, and advanced parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîÑ FLUSH AFTER RETRIEVAL SYSTEM TRACING  \n",
    "# This ensures all @trace_retrieval decorator traces are sent immediately\n",
    "\n",
    "flush_traces(\"Retrieval System Tracing (Vector + Keyword + Hybrid)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced LLM Tracing Examples\n",
    "\n",
    "# Test different LLM providers with comprehensive metadata\n",
    "@trace_llm(provider=\"anthropic\", capture_tokens=True, estimate_costs=True)\n",
    "def call_anthropic(prompt: str, model: str = \"claude-3-haiku\") -> str:\n",
    "    \"\"\"Call Anthropic Claude with tracing.\"\"\"\n",
    "    print(f\"üß† Calling {model} with prompt: {prompt[:50]}...\")\n",
    "    \n",
    "    # Mock Anthropic response\n",
    "    time.sleep(0.4)\n",
    "    responses = [\n",
    "        \"Observability in AI systems provides critical insights into model behavior and performance.\",\n",
    "        \"Tracing AI workflows enables debugging, optimization, and compliance monitoring.\",\n",
    "        \"Comprehensive monitoring helps ensure AI system reliability and user trust.\"\n",
    "    ]\n",
    "    return random.choice(responses)\n",
    "\n",
    "# Test with custom metadata and tags\n",
    "@trace_llm(\n",
    "    provider=\"openai\", \n",
    "    capture_prompts=True, \n",
    "    capture_completions=True,\n",
    "    metadata={\"experiment\": \"demo\", \"version\": \"1.0\"},\n",
    "    tags={\"environment\": \"notebook\", \"user\": \"demo\"}\n",
    ")\n",
    "def call_llm_with_metadata(prompt: str, model: str = \"gpt-4\") -> str:\n",
    "    \"\"\"LLM call with custom metadata and tags.\"\"\"\n",
    "    print(f\"üìã Enhanced LLM call with metadata: {prompt[:40]}...\")\n",
    "    time.sleep(0.3)\n",
    "    return f\"Enhanced response for: {prompt[:20]}...\"\n",
    "\n",
    "# Test Google AI provider\n",
    "@trace_llm(provider=\"google\", capture_tokens=True, redact_pii=True)\n",
    "def call_google_ai(prompt: str, model: str = \"gemini-pro\") -> str:\n",
    "    \"\"\"Call Google AI with PII redaction.\"\"\"\n",
    "    print(f\"üü¢ Calling {model} with PII protection: {prompt[:40]}...\")\n",
    "    time.sleep(0.5)\n",
    "    return \"Google AI response with PII redaction enabled for sensitive data handling.\"\n",
    "\n",
    "# Test various LLM providers\n",
    "print(\"ü§ñ Testing Enhanced LLM Tracing...\")\n",
    "\n",
    "anthropic_response = call_anthropic(\"What are the key benefits of AI observability?\")\n",
    "print(f\"\\nüß† Anthropic Response: {anthropic_response}\")\n",
    "\n",
    "metadata_response = call_llm_with_metadata(\"Summarize the importance of AI monitoring\")\n",
    "print(f\"\\nüìã Enhanced Response: {metadata_response}\")\n",
    "\n",
    "google_response = call_google_ai(\"How does tracing help with AI compliance?\")\n",
    "print(f\"\\nüü¢ Google AI Response: {google_response}\")\n",
    "\n",
    "print(\"\\n‚úÖ Enhanced LLM tracing completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîÑ FLUSH AFTER ENHANCED MULTI-AGENT SYSTEM TRACING\n",
    "# This ensures all @trace_agent decorator traces are sent immediately\n",
    "\n",
    "flush_traces(\"Enhanced Multi-Agent System (Data Analyst + Content Curator + Synthesis + Orchestrator)\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 5.2: Retrieval System Tracing\n",
    "\n",
    "Test retrieval operations with the `@trace_retrieval` decorator for RAG systems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîÑ FLUSH AFTER CONTEXT MANAGERS AND STREAMING\n",
    "# This ensures all context manager traces are sent immediately\n",
    "\n",
    "flush_traces(\"Context Managers and Streaming (trace_llm_call + trace_agent_operation + trace_operation + streaming)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the retrieval decorator\n",
    "from noveum_trace import trace_retrieval\n",
    "from typing import Dict, Any, Optional\n",
    "import time\n",
    "\n",
    "# Vector search with comprehensive tracing\n",
    "@trace_retrieval(\n",
    "    retrieval_type=\"vector_search\",\n",
    "    index_name=\"knowledge_base\",\n",
    "    capture_query=True,\n",
    "    capture_results=True,\n",
    "    capture_scores=True,\n",
    "    metadata={\"index_version\": \"v2.1\", \"embedding_model\": \"text-embedding-ada-002\"}\n",
    ")\n",
    "def vector_search(query: str, top_k: int = 5) -> Dict[str, Any]:\n",
    "    \"\"\"Perform vector search with tracing.\"\"\"\n",
    "    print(f\"üîç Vector Search: Finding top {top_k} results for '{query}'\")\n",
    "    \n",
    "    # Simulate vector search\n",
    "    time.sleep(0.3)\n",
    "    \n",
    "    # Mock search results with scores\n",
    "    results = []\n",
    "    for i in range(top_k):\n",
    "        results.append({\n",
    "            \"document_id\": f\"doc_{i+1}\",\n",
    "            \"content\": f\"Relevant content for '{query}' - document {i+1}\",\n",
    "            \"score\": 0.95 - (i * 0.1),\n",
    "            \"metadata\": {\"source\": f\"source_{i+1}.pdf\", \"page\": i+1}\n",
    "        })\n",
    "    \n",
    "    search_result = {\n",
    "        \"query\": query,\n",
    "        \"total_results\": top_k,\n",
    "        \"results\": results,\n",
    "        \"search_time_ms\": 300,\n",
    "        \"index_stats\": {\"total_docs\": 10000, \"dimensions\": 1536}\n",
    "    }\n",
    "    \n",
    "    print(f\"‚úÖ Found {len(results)} relevant documents\")\n",
    "    return search_result\n",
    "\n",
    "# Keyword search with metadata capture\n",
    "@trace_retrieval(\n",
    "    retrieval_type=\"keyword_search\",\n",
    "    index_name=\"text_corpus\",\n",
    "    capture_metadata=True,\n",
    "    tags={\"search_type\": \"fulltext\", \"language\": \"en\"}\n",
    ")\n",
    "def keyword_search(query: str, filters: Optional[Dict] = None) -> Dict[str, Any]:\n",
    "    \"\"\"Perform keyword search with filtering.\"\"\"\n",
    "    print(f\"üîé Keyword Search: '{query}' with filters: {filters}\")\n",
    "    \n",
    "    time.sleep(0.2)\n",
    "    \n",
    "    # Mock keyword search results\n",
    "    results = [\n",
    "        {\"doc_id\": \"kw_1\", \"title\": \"AI Observability Guide\", \"snippet\": \"...observability in AI...\"},\n",
    "        {\"doc_id\": \"kw_2\", \"title\": \"Tracing Best Practices\", \"snippet\": \"...tracing methodologies...\"},\n",
    "        {\"doc_id\": \"kw_3\", \"title\": \"Monitoring AI Systems\", \"snippet\": \"...monitoring strategies...\"}\n",
    "    ]\n",
    "    \n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"filters\": filters or {},\n",
    "        \"results\": results,\n",
    "        \"total_matches\": len(results)\n",
    "    }\n",
    "\n",
    "# Test retrieval operations\n",
    "print(\"üîç Testing Retrieval System Tracing...\")\n",
    "\n",
    "# Test vector search\n",
    "vector_result = vector_search(\"benefits of AI observability\", top_k=3)\n",
    "print(f\"\\nüîç Vector Search Results: {len(vector_result['results'])} documents\")\n",
    "\n",
    "# Test keyword search with filters\n",
    "keyword_result = keyword_search(\"AI monitoring\", filters={\"category\": \"technical\", \"year\": 2024})\n",
    "print(f\"\\nüîé Keyword Search Results: {keyword_result['total_matches']} matches\")\n",
    "\n",
    "print(\"\\n‚úÖ Retrieval tracing completed!\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 6.1: Enhanced Multi-Agent System\n",
    "\n",
    "Test advanced multi-agent workflows with specialized agents and complex coordination patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Multi-Agent System Examples\n",
    "# Import required types to ensure they're available in this cell\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "# Specialized agents with different roles and capabilities\n",
    "@trace_agent(\n",
    "    agent_id=\"data_analyst\",\n",
    "    role=\"analyst\",\n",
    "    agent_type=\"specialist\",\n",
    "    capabilities=[\"data_analysis\", \"statistical_modeling\", \"visualization\"],\n",
    "    capture_reasoning=True,\n",
    "    metadata={\"specialization\": \"quantitative_analysis\", \"confidence_threshold\": 0.8}\n",
    ")\n",
    "def data_analyst_agent(data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Specialized data analysis agent.\"\"\"\n",
    "    print(f\"üìä Data Analyst: Analyzing dataset with {len(data.get('samples', []))} samples\")\n",
    "    \n",
    "    time.sleep(0.5)\n",
    "    \n",
    "    # Mock data analysis\n",
    "    analysis = {\n",
    "        \"agent_id\": \"data_analyst\",\n",
    "        \"analysis_type\": \"quantitative\",\n",
    "        \"findings\": {\n",
    "            \"data_quality\": 0.92,\n",
    "            \"pattern_confidence\": 0.87,\n",
    "            \"anomalies_detected\": 3,\n",
    "            \"recommendations\": [\n",
    "                \"Data quality is high with 92% confidence\",\n",
    "                \"3 anomalies detected requiring investigation\",\n",
    "                \"Statistical patterns show strong correlation\"\n",
    "            ]\n",
    "        },\n",
    "        \"reasoning_steps\": [\n",
    "            \"Loaded and validated input data\",\n",
    "            \"Applied statistical analysis methods\", \n",
    "            \"Identified patterns and anomalies\",\n",
    "            \"Generated confidence-based recommendations\"\n",
    "        ],\n",
    "        \"processing_time\": 0.5\n",
    "    }\n",
    "    \n",
    "    print(f\"‚úÖ Analysis complete: {analysis['findings']['data_quality']:.2f} quality score\")\n",
    "    return analysis\n",
    "\n",
    "@trace_agent(\n",
    "    agent_id=\"content_curator\",\n",
    "    role=\"curator\",\n",
    "    agent_type=\"content_specialist\", \n",
    "    capabilities=[\"content_filtering\", \"quality_assessment\", \"summarization\"],\n",
    "    capture_tools=True\n",
    ")\n",
    "def content_curator_agent(content_list: List[Dict]) -> Dict[str, Any]:\n",
    "    \"\"\"Content curation and quality assessment agent.\"\"\"\n",
    "    print(f\"üìù Content Curator: Processing {len(content_list)} content items\")\n",
    "    \n",
    "    time.sleep(0.4)\n",
    "    \n",
    "    # Mock content curation using tools\n",
    "    high_quality_content = []\n",
    "    for i, content in enumerate(content_list):\n",
    "        if i < 3:  # Mock: keep first 3 as high quality\n",
    "            high_quality_content.append({\n",
    "                **content,\n",
    "                \"quality_score\": 0.9 - (i * 0.05),\n",
    "                \"curation_reason\": \"Meets quality standards\"\n",
    "            })\n",
    "    \n",
    "    curation_result = {\n",
    "        \"agent_id\": \"content_curator\",\n",
    "        \"input_count\": len(content_list),\n",
    "        \"curated_count\": len(high_quality_content),\n",
    "        \"curated_content\": high_quality_content,\n",
    "        \"tools_used\": [\"quality_scorer\", \"content_filter\", \"summarizer\"],\n",
    "        \"curation_metrics\": {\n",
    "            \"retention_rate\": len(high_quality_content) / len(content_list),\n",
    "            \"average_quality\": sum(item[\"quality_score\"] for item in high_quality_content) / len(high_quality_content)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(f\"‚úÖ Curated {len(high_quality_content)}/{len(content_list)} items\")\n",
    "    return curation_result\n",
    "\n",
    "# Test the enhanced multi-agent system\n",
    "print(\"ü§ñ Testing Enhanced Multi-Agent System...\")\n",
    "\n",
    "# Mock data for demonstration\n",
    "sample_data = {\"samples\": [f\"sample_{i}\" for i in range(100)]}\n",
    "sample_content = [\n",
    "    {\"id\": 1, \"title\": \"AI Observability\", \"content\": \"Content about observability\"},\n",
    "    {\"id\": 2, \"title\": \"Tracing Systems\", \"content\": \"Content about tracing\"},\n",
    "    {\"id\": 3, \"title\": \"Monitoring Tools\", \"content\": \"Content about monitoring\"},\n",
    "    {\"id\": 4, \"title\": \"Low Quality\", \"content\": \"Poor content\"}\n",
    "]\n",
    "\n",
    "# Test individual agents\n",
    "analyst_result = data_analyst_agent(sample_data)\n",
    "print(f\"\\nüìä Data Analysis: {analyst_result['findings']['data_quality']:.2f} quality score\")\n",
    "\n",
    "curator_result = content_curator_agent(sample_content)\n",
    "print(f\"\\nüìù Content Curation: {curator_result['curated_count']}/{curator_result['input_count']} items retained\")\n",
    "\n",
    "print(\"\\n‚úÖ Enhanced multi-agent system testing completed!\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 7.1: Context Managers and Streaming\n",
    "\n",
    "Test context managers for inline tracing and streaming LLM responses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import context managers and streaming features\n",
    "from noveum_trace import (\n",
    "    trace_llm_call, trace_agent_operation, trace_operation, \n",
    "    streaming_llm, trace_streaming, ThreadContext\n",
    ")\n",
    "from typing import Dict, Any, Iterator\n",
    "\n",
    "# Context Manager Examples - Inline Tracing\n",
    "\n",
    "def process_user_query_with_context_managers(user_input: str) -> str:\n",
    "    \"\"\"Demonstrate inline tracing with context managers.\"\"\"\n",
    "    print(f\"üîÑ Processing user query: '{user_input[:40]}...'\")\n",
    "    \n",
    "    # Some preprocessing (not traced)\n",
    "    cleaned_input = user_input.strip().lower()\n",
    "    \n",
    "    # Trace just the LLM call using context manager\n",
    "    with trace_llm_call(model=\"gpt-4\", provider=\"openai\", operation=\"query_processing\") as span:\n",
    "        print(\"ü§ñ Making LLM call within context manager...\")\n",
    "        time.sleep(0.4)\n",
    "        \n",
    "        # Mock LLM response\n",
    "        response = f\"Processed response for: {cleaned_input[:30]}...\"\n",
    "        \n",
    "        # Add custom attributes to the span\n",
    "        span.set_attributes({\n",
    "            \"llm.input_length\": len(cleaned_input),\n",
    "            \"llm.output_length\": len(response),\n",
    "            \"llm.processing_type\": \"query_understanding\"\n",
    "        })\n",
    "        \n",
    "        print(f\"‚úÖ LLM response generated: {len(response)} characters\")\n",
    "    \n",
    "    # Post-processing (not traced)\n",
    "    final_response = f\"Final: {response}\"\n",
    "    print(f\"üì§ Final response: {final_response[:50]}...\")\n",
    "    \n",
    "    return final_response\n",
    "\n",
    "# Agent operation context manager\n",
    "def agent_task_with_context_manager(task: str) -> Dict[str, Any]:\n",
    "    \"\"\"Demonstrate agent operation tracing with context manager.\"\"\"\n",
    "    print(f\"ü§ñ Agent Task: '{task}'\")\n",
    "    \n",
    "    with trace_agent_operation(\n",
    "        agent_type=\"task_agent\", \n",
    "        operation=\"task_execution\",\n",
    "        capabilities=[\"task_planning\", \"execution\", \"monitoring\"]\n",
    "    ) as span:\n",
    "        print(\"‚öôÔ∏è  Executing agent task...\")\n",
    "        time.sleep(0.3)\n",
    "        \n",
    "        # Mock agent work\n",
    "        result = {\n",
    "            \"task\": task,\n",
    "            \"status\": \"completed\",\n",
    "            \"steps_executed\": 5,\n",
    "            \"success_rate\": 0.95\n",
    "        }\n",
    "        \n",
    "        # Add agent-specific attributes\n",
    "        span.set_attributes({\n",
    "            \"agent.task_complexity\": \"medium\",\n",
    "            \"agent.steps_executed\": result[\"steps_executed\"],\n",
    "            \"agent.success_rate\": result[\"success_rate\"]\n",
    "        })\n",
    "        \n",
    "        print(f\"‚úÖ Agent task completed with {result['success_rate']:.1%} success rate\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Generic operation context manager (FIXED SYNTAX)\n",
    "def complex_operation_with_tracing() -> Dict[str, Any]:\n",
    "    \"\"\"Demonstrate generic operation tracing.\"\"\"\n",
    "    print(\"üîß Starting complex operation...\")\n",
    "    \n",
    "    # CORRECT SYNTAX: trace_operation(operation_name, attributes=...)\n",
    "    with trace_operation(\"complex_data_processing\", \n",
    "                        attributes={\"operation_type\": \"data_pipeline\", \"complexity\": \"high\"}) as span:\n",
    "        # Step 1: Data loading\n",
    "        print(\"üì• Step 1: Loading data...\")\n",
    "        time.sleep(0.2)\n",
    "        span.set_attributes({\"step\": \"data_loading\", \"records_loaded\": 1000})\n",
    "        \n",
    "        # Step 2: Processing\n",
    "        print(\"‚öôÔ∏è  Step 2: Processing data...\")\n",
    "        time.sleep(0.3)\n",
    "        span.set_attributes({\"step\": \"processing\", \"records_processed\": 950})\n",
    "        \n",
    "        # Step 3: Output\n",
    "        print(\"üì§ Step 3: Generating output...\")\n",
    "        time.sleep(0.1)\n",
    "        span.set_attributes({\"step\": \"output\", \"records_output\": 950})\n",
    "        \n",
    "        result = {\n",
    "            \"operation\": \"complex_data_processing\",\n",
    "            \"input_records\": 1000,\n",
    "            \"processed_records\": 950,\n",
    "            \"success\": True\n",
    "        }\n",
    "        \n",
    "        print(\"‚úÖ Complex operation completed successfully\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Test context managers\n",
    "print(\"üîÑ Testing Context Managers...\")\n",
    "\n",
    "print(\"\\\\n1Ô∏è‚É£ Context Manager Examples:\")\n",
    "query_result = process_user_query_with_context_managers(\"What are the benefits of AI observability?\")\n",
    "\n",
    "agent_result = agent_task_with_context_manager(\"Analyze system performance metrics\")\n",
    "\n",
    "operation_result = complex_operation_with_tracing()\n",
    "\n",
    "print(\"\\\\n‚úÖ Context managers testing completed!\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 7.2: Auto-Instrumentation and Advanced Features\n",
    "\n",
    "Test auto-instrumentation, proxy objects, and advanced SDK features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import advanced features\n",
    "from noveum_trace import (\n",
    "    auto_instrument, get_instrumented_libraries, is_instrumented,\n",
    "    create_traced_openai_client, create_traced_agent, TracedOpenAIClient,\n",
    "    start_trace, start_span, get_current_trace, get_current_span\n",
    ")\n",
    "\n",
    "# Auto-Instrumentation Examples\n",
    "\n",
    "def test_auto_instrumentation():\n",
    "    \"\"\"Test automatic instrumentation of libraries.\"\"\"\n",
    "    print(\"üîß Testing Auto-Instrumentation...\")\n",
    "    \n",
    "    # Check available instrumentations\n",
    "    try:\n",
    "        available = noveum_trace.get_available_instrumentations()\n",
    "        print(f\"üì¶ Available instrumentations: {available}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ÑπÔ∏è  Available instrumentations: {e}\")\n",
    "    \n",
    "    # Enable auto-instrumentation for OpenAI (if not already enabled)\n",
    "    try:\n",
    "        if not is_instrumented(\"openai\"):\n",
    "            print(\"üîå Enabling OpenAI auto-instrumentation...\")\n",
    "            auto_instrument(\"openai\")\n",
    "            print(\"‚úÖ OpenAI auto-instrumentation enabled\")\n",
    "        else:\n",
    "            print(\"‚úÖ OpenAI already instrumented\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ÑπÔ∏è  Auto-instrumentation: {e}\")\n",
    "    \n",
    "    # Check instrumented libraries\n",
    "    try:\n",
    "        instrumented = get_instrumented_libraries()\n",
    "        print(f\"üîç Currently instrumented: {instrumented}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ÑπÔ∏è  Instrumented libraries: {e}\")\n",
    "    \n",
    "    return []\n",
    "\n",
    "# Proxy Objects for Enhanced Control\n",
    "\n",
    "def test_traced_openai_client():\n",
    "    \"\"\"Test traced OpenAI client proxy.\"\"\"\n",
    "    print(\"üîÑ Testing Traced OpenAI Client...\")\n",
    "    \n",
    "    # Create traced OpenAI client (even without real API key)\n",
    "    try:\n",
    "        traced_client = create_traced_openai_client(\n",
    "            api_key=\"mock-key-for-demo\",\n",
    "            trace_completions=True,\n",
    "            trace_embeddings=True,\n",
    "            capture_content=True\n",
    "        )\n",
    "        print(\"‚úÖ Traced OpenAI client created\")\n",
    "        \n",
    "        # Mock a call (won't actually work without real API key)\n",
    "        print(\"ü§ñ Simulating traced OpenAI call...\")\n",
    "        # In real usage: response = traced_client.chat.completions.create(...)\n",
    "        print(\"‚ÑπÔ∏è  Would automatically trace all OpenAI API calls\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ÑπÔ∏è  Traced client demo: {e}\")\n",
    "\n",
    "def test_traced_agent_proxy():\n",
    "    \"\"\"Test traced agent proxy for enhanced agent monitoring.\"\"\"\n",
    "    print(\"ü§ñ Testing Traced Agent Proxy...\")\n",
    "    \n",
    "    # Mock agent class\n",
    "    class MockAgent:\n",
    "        def __init__(self, name: str):\n",
    "            self.name = name\n",
    "        \n",
    "        def think(self, problem: str) -> str:\n",
    "            time.sleep(0.2)\n",
    "            return f\"Thinking about: {problem}\"\n",
    "        \n",
    "        def act(self, action: str) -> str:\n",
    "            time.sleep(0.3)\n",
    "            return f\"Performing action: {action}\"\n",
    "        \n",
    "        def plan(self, goal: str) -> List[str]:\n",
    "            time.sleep(0.4)\n",
    "            return [f\"Step 1 for {goal}\", f\"Step 2 for {goal}\", f\"Step 3 for {goal}\"]\n",
    "    \n",
    "    # Create traced agent proxy with CORRECT PARAMETERS\n",
    "    original_agent = MockAgent(\"demo_agent\")\n",
    "    traced_agent = create_traced_agent(\n",
    "        agent=original_agent,\n",
    "        agent_type=\"traced_demo_agent\",  # CORRECT: agent_type instead of agent_id\n",
    "        capabilities=[\"thinking\", \"acting\", \"planning\"],\n",
    "        trace_config={\"capture_inputs\": True, \"capture_outputs\": True}\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Traced agent proxy created\")\n",
    "    \n",
    "    # Test traced methods\n",
    "    print(\"üß† Testing traced agent methods...\")\n",
    "    \n",
    "    thought = traced_agent.think(\"How to improve AI observability\")\n",
    "    print(f\"üí≠ Think result: {thought}\")\n",
    "    \n",
    "    action = traced_agent.act(\"Implement monitoring dashboard\")\n",
    "    print(f\"‚ö° Action result: {action}\")\n",
    "    \n",
    "    plan = traced_agent.plan(\"Enhance system reliability\")\n",
    "    print(f\"üìã Plan result: {len(plan)} steps\")\n",
    "\n",
    "# Manual Span Creation and Management\n",
    "\n",
    "def test_manual_tracing():\n",
    "    \"\"\"Test manual trace and span creation.\"\"\"\n",
    "    print(\"üîç Testing Manual Tracing...\")\n",
    "    \n",
    "    try:\n",
    "        # Start a manual trace\n",
    "        trace = start_trace(\"manual_demo_trace\")\n",
    "        print(f\"‚úÖ Started trace: {trace.trace_id}\")\n",
    "        \n",
    "        # Create nested spans manually\n",
    "        with trace.span(\"parent_operation\") as parent_span:\n",
    "            parent_span.set_attributes({\n",
    "                \"operation.type\": \"parent\",\n",
    "                \"operation.importance\": \"high\"\n",
    "            })\n",
    "            print(\"üìä Parent span created\")\n",
    "            \n",
    "            # Child span 1\n",
    "            with parent_span.create_child_span(\"child_operation_1\") as child1:\n",
    "                child1.set_attributes({\n",
    "                    \"operation.type\": \"child\",\n",
    "                    \"child.number\": 1\n",
    "                })\n",
    "                time.sleep(0.2)\n",
    "                print(\"üîπ Child span 1 completed\")\n",
    "            \n",
    "            # Child span 2  \n",
    "            with parent_span.create_child_span(\"child_operation_2\") as child2:\n",
    "                child2.set_attributes({\n",
    "                    \"operation.type\": \"child\",\n",
    "                    \"child.number\": 2,\n",
    "                    \"child.data_processed\": 500\n",
    "                })\n",
    "                time.sleep(0.3)\n",
    "                print(\"üîπ Child span 2 completed\")\n",
    "            \n",
    "            print(\"üìä Parent operation completed\")\n",
    "        \n",
    "        # Finish trace\n",
    "        trace.finish()\n",
    "        print(f\"‚úÖ Manual trace completed: {trace.trace_id}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ÑπÔ∏è  Manual tracing demo: {e}\")\n",
    "\n",
    "# Error Handling and Edge Cases\n",
    "\n",
    "def test_error_handling():\n",
    "    \"\"\"Test error handling and edge cases.\"\"\"\n",
    "    print(\"‚ö†Ô∏è  Testing Error Handling...\")\n",
    "    \n",
    "    # Test error capture in traced function\n",
    "    @noveum_trace.trace(capture_errors=True, capture_stack_trace=True)\n",
    "    def operation_with_error(should_fail: bool = False):\n",
    "        if should_fail:\n",
    "            raise ValueError(\"This is a demo error for testing\")\n",
    "        return \"Success!\"\n",
    "    \n",
    "    # Test successful operation\n",
    "    try:\n",
    "        result = operation_with_error(should_fail=False)\n",
    "        print(f\"‚úÖ Successful operation: {result}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Unexpected error: {e}\")\n",
    "    \n",
    "    # Test error capture\n",
    "    try:\n",
    "        result = operation_with_error(should_fail=True)\n",
    "        print(f\"Unexpected success: {result}\")\n",
    "    except ValueError as e:\n",
    "        print(f\"‚úÖ Error captured successfully: {e}\")\n",
    "\n",
    "# Run all advanced feature tests\n",
    "print(\"üöÄ Testing Auto-Instrumentation and Advanced Features...\")\n",
    "\n",
    "print(\"\\\\n1Ô∏è‚É£ Auto-Instrumentation:\")\n",
    "instrumented_libs = test_auto_instrumentation()\n",
    "\n",
    "print(\"\\\\n2Ô∏è‚É£ Proxy Objects:\")\n",
    "test_traced_openai_client()\n",
    "test_traced_agent_proxy()\n",
    "\n",
    "print(\"\\\\n3Ô∏è‚É£ Manual Tracing:\")\n",
    "test_manual_tracing()\n",
    "\n",
    "print(\"\\\\n4Ô∏è‚É£ Error Handling:\")\n",
    "test_error_handling()\n",
    "\n",
    "print(\"\\\\n‚úÖ Advanced features testing completed!\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 5.1: Enhanced LLM Tracing Examples\n",
    "\n",
    "Demonstrate various LLM tracing features including different providers, metadata, and advanced parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced LLM Tracing Examples\n",
    "\n",
    "# Test different LLM providers with comprehensive metadata\n",
    "@trace_llm(provider=\"anthropic\", capture_tokens=True, estimate_costs=True)\n",
    "def call_anthropic(prompt: str, model: str = \"claude-3-haiku\") -> str:\n",
    "    \"\"\"Call Anthropic Claude with tracing.\"\"\"\n",
    "    print(f\"üß† Calling {model} with prompt: {prompt[:50]}...\")\n",
    "    \n",
    "    # Mock Anthropic response\n",
    "    time.sleep(0.4)\n",
    "    responses = [\n",
    "        \"Observability in AI systems provides critical insights into model behavior and performance.\",\n",
    "        \"Tracing AI workflows enables debugging, optimization, and compliance monitoring.\",\n",
    "        \"Comprehensive monitoring helps ensure AI system reliability and user trust.\"\n",
    "    ]\n",
    "    return random.choice(responses)\n",
    "\n",
    "# Test with custom metadata and tags\n",
    "@trace_llm(\n",
    "    provider=\"openai\", \n",
    "    capture_prompts=True, \n",
    "    capture_completions=True,\n",
    "    metadata={\"experiment\": \"demo\", \"version\": \"1.0\"},\n",
    "    tags={\"environment\": \"notebook\", \"user\": \"demo\"}\n",
    ")\n",
    "def call_llm_with_metadata(prompt: str, model: str = \"gpt-4\") -> str:\n",
    "    \"\"\"LLM call with custom metadata and tags.\"\"\"\n",
    "    print(f\"üìã Enhanced LLM call with metadata: {prompt[:40]}...\")\n",
    "    time.sleep(0.3)\n",
    "    return f\"Enhanced response for: {prompt[:20]}...\"\n",
    "\n",
    "# Test Google AI provider\n",
    "@trace_llm(provider=\"google\", capture_tokens=True, redact_pii=True)\n",
    "def call_google_ai(prompt: str, model: str = \"gemini-pro\") -> str:\n",
    "    \"\"\"Call Google AI with PII redaction.\"\"\"\n",
    "    print(f\"üü¢ Calling {model} with PII protection: {prompt[:40]}...\")\n",
    "    time.sleep(0.5)\n",
    "    return \"Google AI response with PII redaction enabled for sensitive data handling.\"\n",
    "\n",
    "# Test various LLM providers\n",
    "print(\"ü§ñ Testing Enhanced LLM Tracing...\")\n",
    "\n",
    "anthropic_response = call_anthropic(\"What are the key benefits of AI observability?\")\n",
    "print(f\"\\nüß† Anthropic Response: {anthropic_response}\")\n",
    "\n",
    "metadata_response = call_llm_with_metadata(\"Summarize the importance of AI monitoring\")\n",
    "print(f\"\\nüìã Enhanced Response: {metadata_response}\")\n",
    "\n",
    "google_response = call_google_ai(\"How does tracing help with AI compliance?\")\n",
    "print(f\"\\nüü¢ Google AI Response: {google_response}\")\n",
    "\n",
    "print(\"\\n‚úÖ Enhanced LLM tracing completed!\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 5.2: Retrieval System Tracing\n",
    "\n",
    "Test retrieval operations with the `@trace_retrieval` decorator for RAG systems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîÑ FLUSH AFTER CORRECTED TRACE_OPERATION EXAMPLES\n",
    "# This ensures all corrected context manager traces are sent immediately\n",
    "\n",
    "flush_traces(\"Corrected trace_operation Examples (Fixed Syntax)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the retrieval decorator and missing typing imports\n",
    "from noveum_trace import trace_retrieval\n",
    "from typing import Dict, Any, Optional, List, Iterator\n",
    "\n",
    "# Vector search with comprehensive tracing\n",
    "@trace_retrieval(\n",
    "    retrieval_type=\"vector_search\",\n",
    "    index_name=\"knowledge_base\",\n",
    "    capture_query=True,\n",
    "    capture_results=True,\n",
    "    capture_scores=True,\n",
    "    metadata={\"index_version\": \"v2.1\", \"embedding_model\": \"text-embedding-ada-002\"}\n",
    ")\n",
    "def vector_search(query: str, top_k: int = 5) -> Dict[str, Any]:\n",
    "    \"\"\"Perform vector search with tracing.\"\"\"\n",
    "    print(f\"üîç Vector Search: Finding top {top_k} results for '{query}'\")\n",
    "    \n",
    "    # Simulate vector search\n",
    "    time.sleep(0.3)\n",
    "    \n",
    "    # Mock search results with scores\n",
    "    results = []\n",
    "    for i in range(top_k):\n",
    "        results.append({\n",
    "            \"document_id\": f\"doc_{i+1}\",\n",
    "            \"content\": f\"Relevant content for '{query}' - document {i+1}\",\n",
    "            \"score\": 0.95 - (i * 0.1),\n",
    "            \"metadata\": {\"source\": f\"source_{i+1}.pdf\", \"page\": i+1}\n",
    "        })\n",
    "    \n",
    "    search_result = {\n",
    "        \"query\": query,\n",
    "        \"total_results\": top_k,\n",
    "        \"results\": results,\n",
    "        \"search_time_ms\": 300,\n",
    "        \"index_stats\": {\"total_docs\": 10000, \"dimensions\": 1536}\n",
    "    }\n",
    "    \n",
    "    print(f\"‚úÖ Found {len(results)} relevant documents\")\n",
    "    return search_result\n",
    "\n",
    "# Keyword search with metadata capture\n",
    "@trace_retrieval(\n",
    "    retrieval_type=\"keyword_search\",\n",
    "    index_name=\"text_corpus\",\n",
    "    capture_metadata=True,\n",
    "    tags={\"search_type\": \"fulltext\", \"language\": \"en\"}\n",
    ")\n",
    "def keyword_search(query: str, filters: Optional[Dict] = None) -> Dict[str, Any]:\n",
    "    \"\"\"Perform keyword search with filtering.\"\"\"\n",
    "    print(f\"üîé Keyword Search: '{query}' with filters: {filters}\")\n",
    "    \n",
    "    time.sleep(0.2)\n",
    "    \n",
    "    # Mock keyword search results\n",
    "    results = [\n",
    "        {\"doc_id\": \"kw_1\", \"title\": \"AI Observability Guide\", \"snippet\": \"...observability in AI...\"},\n",
    "        {\"doc_id\": \"kw_2\", \"title\": \"Tracing Best Practices\", \"snippet\": \"...tracing methodologies...\"},\n",
    "        {\"doc_id\": \"kw_3\", \"title\": \"Monitoring AI Systems\", \"snippet\": \"...monitoring strategies...\"}\n",
    "    ]\n",
    "    \n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"filters\": filters or {},\n",
    "        \"results\": results,\n",
    "        \"total_matches\": len(results)\n",
    "    }\n",
    "\n",
    "# Hybrid search combining vector and keyword\n",
    "@trace_retrieval(\n",
    "    retrieval_type=\"hybrid_search\",\n",
    "    index_name=\"hybrid_index\",\n",
    "    capture_query=True,\n",
    "    capture_results=True,\n",
    "    capture_scores=True\n",
    ")\n",
    "def hybrid_search(query: str, alpha: float = 0.5) -> Dict[str, Any]:\n",
    "    \"\"\"Perform hybrid search combining vector and keyword search.\"\"\"\n",
    "    print(f\"üîó Hybrid Search: '{query}' with alpha={alpha}\")\n",
    "    \n",
    "    time.sleep(0.4)\n",
    "    \n",
    "    # Simulate hybrid search by combining both approaches\n",
    "    vector_results = vector_search(query, top_k=3)\n",
    "    keyword_results = keyword_search(query)\n",
    "    \n",
    "    # Mock hybrid ranking\n",
    "    hybrid_results = []\n",
    "    for i, result in enumerate(vector_results[\"results\"][:2]):\n",
    "        hybrid_results.append({\n",
    "            \"document_id\": result[\"document_id\"],\n",
    "            \"content\": result[\"content\"],\n",
    "            \"vector_score\": result[\"score\"],\n",
    "            \"keyword_score\": 0.8 - (i * 0.1),\n",
    "            \"combined_score\": (result[\"score\"] * alpha) + ((0.8 - i * 0.1) * (1 - alpha)),\n",
    "            \"source\": \"hybrid\"\n",
    "        })\n",
    "    \n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"alpha\": alpha,\n",
    "        \"results\": hybrid_results,\n",
    "        \"total_results\": len(hybrid_results),\n",
    "        \"search_strategy\": \"vector + keyword fusion\"\n",
    "    }\n",
    "\n",
    "# Test all retrieval operations\n",
    "print(\"üîç Testing Retrieval System Tracing...\")\n",
    "\n",
    "# Test vector search\n",
    "vector_result = vector_search(\"benefits of AI observability\", top_k=3)\n",
    "print(f\"\\nüîç Vector Search Results: {len(vector_result['results'])} documents\")\n",
    "\n",
    "# Test keyword search with filters\n",
    "keyword_result = keyword_search(\"AI monitoring\", filters={\"category\": \"technical\", \"year\": 2024})\n",
    "print(f\"\\nüîé Keyword Search Results: {keyword_result['total_matches']} matches\")\n",
    "\n",
    "# Test hybrid search\n",
    "hybrid_result = hybrid_search(\"observability tracing systems\", alpha=0.7)\n",
    "print(f\"\\nüîó Hybrid Search Results: {len(hybrid_result['results'])} combined results\")\n",
    "\n",
    "print(\"\\n‚úÖ Retrieval tracing completed!\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 6.1: Enhanced Multi-Agent System\n",
    "\n",
    "Test advanced multi-agent workflows with specialized agents and complex coordination patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîÑ FLUSH AFTER CORRECTED PROXY OBJECT EXAMPLES\n",
    "# This ensures all corrected proxy object traces are sent immediately\n",
    "\n",
    "flush_traces(\"Corrected Proxy Objects (create_traced_agent + create_traced_openai_client)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Multi-Agent System Examples\n",
    "# Import missing typing if not already available\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "# Specialized agents with different roles and capabilities\n",
    "@trace_agent(\n",
    "    agent_id=\"data_analyst\",\n",
    "    role=\"analyst\",\n",
    "    agent_type=\"specialist\",\n",
    "    capabilities=[\"data_analysis\", \"statistical_modeling\", \"visualization\"],\n",
    "    capture_reasoning=True,\n",
    "    metadata={\"specialization\": \"quantitative_analysis\", \"confidence_threshold\": 0.8}\n",
    ")\n",
    "def data_analyst_agent(data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Specialized data analysis agent.\"\"\"\n",
    "    print(f\"üìä Data Analyst: Analyzing dataset with {len(data.get('samples', []))} samples\")\n",
    "    \n",
    "    time.sleep(0.5)\n",
    "    \n",
    "    # Mock data analysis\n",
    "    analysis = {\n",
    "        \"agent_id\": \"data_analyst\",\n",
    "        \"analysis_type\": \"quantitative\",\n",
    "        \"findings\": {\n",
    "            \"data_quality\": 0.92,\n",
    "            \"pattern_confidence\": 0.87,\n",
    "            \"anomalies_detected\": 3,\n",
    "            \"recommendations\": [\n",
    "                \"Data quality is high with 92% confidence\",\n",
    "                \"3 anomalies detected requiring investigation\",\n",
    "                \"Statistical patterns show strong correlation\"\n",
    "            ]\n",
    "        },\n",
    "        \"reasoning_steps\": [\n",
    "            \"Loaded and validated input data\",\n",
    "            \"Applied statistical analysis methods\",\n",
    "            \"Identified patterns and anomalies\",\n",
    "            \"Generated confidence-based recommendations\"\n",
    "        ],\n",
    "        \"processing_time\": 0.5\n",
    "    }\n",
    "    \n",
    "    print(f\"‚úÖ Analysis complete: {analysis['findings']['data_quality']:.2f} quality score\")\n",
    "    return analysis\n",
    "\n",
    "@trace_agent(\n",
    "    agent_id=\"content_curator\",\n",
    "    role=\"curator\",\n",
    "    agent_type=\"content_specialist\",\n",
    "    capabilities=[\"content_filtering\", \"quality_assessment\", \"summarization\"],\n",
    "    capture_tools=True\n",
    ")\n",
    "def content_curator_agent(content_list: List[Dict]) -> Dict[str, Any]:\n",
    "    \"\"\"Content curation and quality assessment agent.\"\"\"\n",
    "    print(f\"üìù Content Curator: Processing {len(content_list)} content items\")\n",
    "    \n",
    "    time.sleep(0.4)\n",
    "    \n",
    "    # Mock content curation using tools\n",
    "    high_quality_content = []\n",
    "    for i, content in enumerate(content_list):\n",
    "        if i < 3:  # Mock: keep first 3 as high quality\n",
    "            high_quality_content.append({\n",
    "                **content,\n",
    "                \"quality_score\": 0.9 - (i * 0.05),\n",
    "                \"curation_reason\": \"Meets quality standards\"\n",
    "            })\n",
    "    \n",
    "    curation_result = {\n",
    "        \"agent_id\": \"content_curator\",\n",
    "        \"input_count\": len(content_list),\n",
    "        \"curated_count\": len(high_quality_content),\n",
    "        \"curated_content\": high_quality_content,\n",
    "        \"tools_used\": [\"quality_scorer\", \"content_filter\", \"summarizer\"],\n",
    "        \"curation_metrics\": {\n",
    "            \"retention_rate\": len(high_quality_content) / len(content_list),\n",
    "            \"average_quality\": sum(item[\"quality_score\"] for item in high_quality_content) / len(high_quality_content)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(f\"‚úÖ Curated {len(high_quality_content)}/{len(content_list)} items\")\n",
    "    return curation_result\n",
    "\n",
    "@trace_agent(\n",
    "    agent_id=\"synthesis_agent\",\n",
    "    role=\"synthesizer\",\n",
    "    agent_type=\"integration_specialist\", \n",
    "    capabilities=[\"multi_source_synthesis\", \"insight_generation\", \"report_creation\"],\n",
    "    capture_inputs=True,\n",
    "    capture_outputs=True\n",
    ")\n",
    "def synthesis_agent(analyst_data: Dict, curator_data: Dict, context: str) -> Dict[str, Any]:\n",
    "    \"\"\"Agent that synthesizes insights from multiple sources.\"\"\"\n",
    "    print(f\"üîó Synthesis Agent: Combining insights for context '{context}'\")\n",
    "    \n",
    "    time.sleep(0.6)\n",
    "    \n",
    "    # Synthesize insights from multiple agents\n",
    "    synthesis = {\n",
    "        \"agent_id\": \"synthesis_agent\",\n",
    "        \"context\": context,\n",
    "        \"input_sources\": [\"data_analyst\", \"content_curator\"],\n",
    "        \"synthesis_insights\": [\n",
    "            f\"Data quality score of {analyst_data['findings']['data_quality']:.2f} indicates reliable foundation\",\n",
    "            f\"Content curation retained {curator_data['curated_count']}/{curator_data['input_count']} high-quality items\",\n",
    "            \"Cross-analysis reveals consistent quality patterns across data and content\",\n",
    "            \"Synthesis confidence: High based on convergent evidence\"\n",
    "        ],\n",
    "        \"combined_metrics\": {\n",
    "            \"data_quality\": analyst_data['findings']['data_quality'],\n",
    "            \"content_quality\": curator_data['curation_metrics']['average_quality'],\n",
    "            \"overall_confidence\": (analyst_data['findings']['pattern_confidence'] + \n",
    "                                 curator_data['curation_metrics']['average_quality']) / 2\n",
    "        },\n",
    "        \"final_recommendation\": \"Proceed with high confidence based on quality convergence\"\n",
    "    }\n",
    "    \n",
    "    print(f\"‚úÖ Synthesis complete with {synthesis['combined_metrics']['overall_confidence']:.2f} confidence\")\n",
    "    return synthesis\n",
    "\n",
    "# Advanced orchestrator with dependency management\n",
    "@trace_agent(\n",
    "    agent_id=\"advanced_orchestrator\",\n",
    "    role=\"coordinator\", \n",
    "    agent_type=\"orchestrator\",\n",
    "    capabilities=[\"workflow_management\", \"dependency_resolution\", \"result_aggregation\"],\n",
    "    capture_reasoning=True,\n",
    "    metadata={\"orchestration_strategy\": \"parallel_with_dependencies\"}\n",
    ")\n",
    "def advanced_orchestrator(task: str, data_context: Dict) -> Dict[str, Any]:\n",
    "    \"\"\"Advanced orchestrator managing complex multi-agent workflows.\"\"\"\n",
    "    print(f\"üé≠ Advanced Orchestrator: Managing workflow for '{task}'\")\n",
    "    \n",
    "    # Phase 1: Parallel execution of independent agents\n",
    "    print(\"\\nüîÑ Phase 1: Parallel Agent Execution\")\n",
    "    \n",
    "    # Mock data for demonstration\n",
    "    sample_data = {\"samples\": [f\"sample_{i}\" for i in range(100)]}\n",
    "    sample_content = [\n",
    "        {\"id\": 1, \"title\": \"AI Observability\", \"content\": \"Content about observability\"},\n",
    "        {\"id\": 2, \"title\": \"Tracing Systems\", \"content\": \"Content about tracing\"},\n",
    "        {\"id\": 3, \"title\": \"Monitoring Tools\", \"content\": \"Content about monitoring\"},\n",
    "        {\"id\": 4, \"title\": \"Low Quality\", \"content\": \"Poor content\"}\n",
    "    ]\n",
    "    \n",
    "    # Execute agents in parallel (simulated)\n",
    "    analyst_result = data_analyst_agent(sample_data)\n",
    "    curator_result = content_curator_agent(sample_content)\n",
    "    \n",
    "    # Phase 2: Synthesis based on results\n",
    "    print(\"\\\\nüîó Phase 2: Synthesis and Integration\")\n",
    "    synthesis_result = synthesis_agent(analyst_result, curator_result, task)\n",
    "    \n",
    "    # Final orchestration result\n",
    "    orchestration_result = {\n",
    "        \"task\": task,\n",
    "        \"orchestration_id\": \"adv_orch_001\",\n",
    "        \"phases\": {\n",
    "            \"analysis\": analyst_result,\n",
    "            \"curation\": curator_result, \n",
    "            \"synthesis\": synthesis_result\n",
    "        },\n",
    "        \"workflow_metrics\": {\n",
    "            \"total_agents\": 3,\n",
    "            \"execution_phases\": 2,\n",
    "            \"final_confidence\": synthesis_result[\"combined_metrics\"][\"overall_confidence\"],\n",
    "            \"workflow_success\": True\n",
    "        },\n",
    "        \"reasoning\": [\n",
    "            \"Initiated parallel execution of specialist agents\",\n",
    "            \"Data analyst provided quantitative insights\",\n",
    "            \"Content curator filtered and assessed quality\",\n",
    "            \"Synthesis agent combined multi-source insights\",\n",
    "            \"Workflow completed with high confidence\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    print(f\"\\\\n‚úÖ Advanced orchestration complete!\")\n",
    "    return orchestration_result\n",
    "\n",
    "# Test the enhanced multi-agent system\n",
    "print(\"ü§ñ Testing Enhanced Multi-Agent System...\")\n",
    "\n",
    "# Run the advanced workflow\n",
    "task = \"Comprehensive analysis of AI system observability data and content\"\n",
    "context_data = {\"domain\": \"ai_observability\", \"priority\": \"high\"}\n",
    "\n",
    "workflow_result = advanced_orchestrator(task, context_data)\n",
    "\n",
    "print(\"\\\\nüé≠ Enhanced Multi-Agent Results:\")\n",
    "print(f\"Task: {workflow_result['task']}\")\n",
    "print(f\"Agents: {workflow_result['workflow_metrics']['total_agents']}\")\n",
    "print(f\"Phases: {workflow_result['workflow_metrics']['execution_phases']}\")\n",
    "print(f\"Final Confidence: {workflow_result['workflow_metrics']['final_confidence']:.2f}\")\n",
    "print(f\"Success: {workflow_result['workflow_metrics']['workflow_success']}\")\n",
    "\n",
    "print(\"\\\\n‚úÖ Enhanced multi-agent system testing completed!\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 7.1: Context Managers and Streaming\n",
    "\n",
    "Test context managers for inline tracing and streaming LLM responses.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## üéØ Comprehensive Demo Summary\n",
    "\n",
    "This notebook provides a **complete demonstration** of the Noveum Trace SDK capabilities:\n",
    "\n",
    "### üé® All Available Decorators:\n",
    "- `@trace` - General purpose function tracing\n",
    "- `@trace_llm` - LLM call tracing with provider-specific features\n",
    "- `@trace_agent` - Agent workflow tracing with role-based capabilities\n",
    "- `@trace_tool` - Tool usage tracing with comprehensive metadata\n",
    "- `@trace_retrieval` - Retrieval operation tracing for RAG systems\n",
    "\n",
    "### üîÑ Context Managers for Inline Tracing:\n",
    "- `trace_llm_call()` - LLM operations within existing functions\n",
    "- `trace_agent_operation()` - Agent tasks with custom attributes\n",
    "- `trace_operation()` - Generic operations with step-by-step tracking\n",
    "- `streaming_llm()` - Real-time streaming LLM response tracing\n",
    "- `ThreadContext()` - Conversation thread management\n",
    "\n",
    "### ü§ñ Multi-Agent System Features:\n",
    "- Basic orchestration patterns\n",
    "- Advanced multi-agent workflows with specialized roles\n",
    "- Dependency management between agents\n",
    "- Parallel execution and result synthesis\n",
    "- Agent capability tracking and reasoning capture\n",
    "\n",
    "### üåä Streaming & Real-time Features:\n",
    "- Token-by-token streaming trace capture\n",
    "- Real-time metrics (tokens/second, time to first token)\n",
    "- Stream metadata and performance analysis\n",
    "- Context-aware streaming within conversations\n",
    "\n",
    "### üöÄ Advanced SDK Features:\n",
    "- Auto-instrumentation for seamless integration\n",
    "- Proxy objects for enhanced control and monitoring\n",
    "- Manual trace/span creation for custom workflows\n",
    "- Batch processing and performance optimization\n",
    "- Configuration management and debugging tools\n",
    "- Comprehensive error handling and edge case testing\n",
    "\n",
    "### üìä Integration Examples:\n",
    "- OpenAI API integration with cost estimation\n",
    "- Anthropic Claude integration with PII redaction\n",
    "- Google AI integration examples\n",
    "- RAG system integration (vector, keyword, hybrid search)\n",
    "- Multi-provider LLM support patterns\n",
    "\n",
    "This comprehensive demo showcases **every major feature** of the Noveum Trace SDK, making it the perfect reference for implementing observability in your AI applications! üöÄ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîÑ FLUSH AFTER ENHANCED SDK INITIALIZATION AND ENDPOINT TESTING\n",
    "# This ensures the endpoint connectivity test traces are sent immediately\n",
    "\n",
    "flush_traces(\"Enhanced SDK Initialization and Endpoint Testing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import context managers and streaming features\n",
    "from noveum_trace import (\n",
    "    trace_llm_call, trace_agent_operation, trace_operation, \n",
    "    streaming_llm, trace_streaming, ThreadContext\n",
    ")\n",
    "\n",
    "# Context Manager Examples - Inline Tracing\n",
    "\n",
    "def process_user_query_with_context_managers(user_input: str) -> str:\n",
    "    \"\"\"Demonstrate inline tracing with context managers.\"\"\"\n",
    "    print(f\"üîÑ Processing user query: '{user_input[:40]}...'\")\n",
    "    \n",
    "    # Some preprocessing (not traced)\n",
    "    cleaned_input = user_input.strip().lower()\n",
    "    \n",
    "    # Trace just the LLM call using context manager\n",
    "    with trace_llm_call(model=\"gpt-4\", provider=\"openai\", operation=\"query_processing\") as span:\n",
    "        print(\"ü§ñ Making LLM call within context manager...\")\n",
    "        time.sleep(0.4)\n",
    "        \n",
    "        # Mock LLM response\n",
    "        response = f\"Processed response for: {cleaned_input[:30]}...\"\n",
    "        \n",
    "        # Add custom attributes to the span\n",
    "        span.set_attributes({\n",
    "            \"llm.input_length\": len(cleaned_input),\n",
    "            \"llm.output_length\": len(response),\n",
    "            \"llm.processing_type\": \"query_understanding\"\n",
    "        })\n",
    "        \n",
    "        print(f\"‚úÖ LLM response generated: {len(response)} characters\")\n",
    "    \n",
    "    # Post-processing (not traced)\n",
    "    final_response = f\"Final: {response}\"\n",
    "    print(f\"üì§ Final response: {final_response[:50]}...\")\n",
    "    \n",
    "    return final_response\n",
    "\n",
    "# Agent operation context manager\n",
    "def agent_task_with_context_manager(task: str) -> Dict[str, Any]:\n",
    "    \"\"\"Demonstrate agent operation tracing with context manager.\"\"\"\n",
    "    print(f\"ü§ñ Agent Task: '{task}'\")\n",
    "    \n",
    "    with trace_agent_operation(\n",
    "        agent_type=\"task_agent\", \n",
    "        operation=\"task_execution\",\n",
    "        capabilities=[\"task_planning\", \"execution\", \"monitoring\"]\n",
    "    ) as span:\n",
    "        print(\"‚öôÔ∏è  Executing agent task...\")\n",
    "        time.sleep(0.3)\n",
    "        \n",
    "        # Mock agent work\n",
    "        result = {\n",
    "            \"task\": task,\n",
    "            \"status\": \"completed\",\n",
    "            \"steps_executed\": 5,\n",
    "            \"success_rate\": 0.95\n",
    "        }\n",
    "        \n",
    "        # Add agent-specific attributes\n",
    "        span.set_attributes({\n",
    "            \"agent.task_complexity\": \"medium\",\n",
    "            \"agent.steps_executed\": result[\"steps_executed\"],\n",
    "            \"agent.success_rate\": result[\"success_rate\"]\n",
    "        })\n",
    "        \n",
    "        print(f\"‚úÖ Agent task completed with {result['success_rate']:.1%} success rate\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Generic operation context manager\n",
    "def complex_operation_with_tracing() -> Dict[str, Any]:\n",
    "    \"\"\"Demonstrate generic operation tracing.\"\"\"\n",
    "    print(\"üîß Starting complex operation...\")\n",
    "    \n",
    "    with trace_operation(operation_name=\"complex_data_processing\") as span:\n",
    "        # Step 1: Data loading\n",
    "        print(\"üì• Step 1: Loading data...\")\n",
    "        time.sleep(0.2)\n",
    "        span.set_attributes({\"step\": \"data_loading\", \"records_loaded\": 1000})\n",
    "        \n",
    "        # Step 2: Processing\n",
    "        print(\"‚öôÔ∏è  Step 2: Processing data...\")\n",
    "        time.sleep(0.3)\n",
    "        span.set_attributes({\"step\": \"processing\", \"records_processed\": 950})\n",
    "        \n",
    "        # Step 3: Output\n",
    "        print(\"üì§ Step 3: Generating output...\")\n",
    "        time.sleep(0.1)\n",
    "        span.set_attributes({\"step\": \"output\", \"records_output\": 950})\n",
    "        \n",
    "        result = {\n",
    "            \"operation\": \"complex_data_processing\",\n",
    "            \"input_records\": 1000,\n",
    "            \"processed_records\": 950,\n",
    "            \"success\": True\n",
    "        }\n",
    "        \n",
    "        print(\"‚úÖ Complex operation completed successfully\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Streaming LLM Examples\n",
    "\n",
    "class MockStreamChunk:\n",
    "    \"\"\"Mock streaming response chunk.\"\"\"\n",
    "    def __init__(self, content: str):\n",
    "        self.choices = [MockChoice(content)]\n",
    "\n",
    "class MockChoice:\n",
    "    \"\"\"Mock choice in streaming response.\"\"\"\n",
    "    def __init__(self, content: str):\n",
    "        self.delta = MockDelta(content)\n",
    "\n",
    "class MockDelta:\n",
    "    \"\"\"Mock delta content.\"\"\"\n",
    "    def __init__(self, content: str):\n",
    "        self.content = content\n",
    "\n",
    "def mock_streaming_response(prompt: str) -> Iterator[MockStreamChunk]:\n",
    "    \"\"\"Generate mock streaming response.\"\"\"\n",
    "    words = f\"This is a streaming response to: {prompt}. Each word comes separately.\".split()\n",
    "    for word in words:\n",
    "        time.sleep(0.05)  # Simulate streaming delay\n",
    "        yield MockStreamChunk(word + \" \")\n",
    "\n",
    "def test_streaming_with_context_manager(prompt: str) -> str:\n",
    "    \"\"\"Test streaming LLM with context manager.\"\"\"\n",
    "    print(f\"üåä Streaming LLM call: '{prompt[:30]}...'\")\n",
    "    \n",
    "    # Create mock stream\n",
    "    stream = mock_streaming_response(prompt)\n",
    "    \n",
    "    # Use streaming context manager\n",
    "    with streaming_llm(model=\"gpt-4\", provider=\"openai\", operation=\"streaming_chat\") as stream_manager:\n",
    "        print(\"üì∫ Streaming response: \", end=\"\")\n",
    "        full_response = \"\"\n",
    "        \n",
    "        for chunk in stream:\n",
    "            token = chunk.choices[0].delta.content\n",
    "            if token:\n",
    "                # Add token to stream manager for tracing\n",
    "                stream_manager.add_token(token)\n",
    "                print(token, end=\"\")\n",
    "                full_response += token\n",
    "        \n",
    "        # Add final metadata\n",
    "        stream_manager.add_metadata({\n",
    "            \"streaming.final_length\": len(full_response),\n",
    "            \"streaming.total_chunks\": len(full_response.split())\n",
    "        })\n",
    "        \n",
    "        print(f\"\\\\n‚úÖ Streaming completed: {len(full_response)} characters\")\n",
    "    \n",
    "    return full_response.strip()\n",
    "\n",
    "# Thread Context for Conversation Tracking\n",
    "\n",
    "def test_thread_context_conversation() -> None:\n",
    "    \"\"\"Test conversation thread tracking.\"\"\"\n",
    "    print(\"üí¨ Testing Thread Context for Conversations...\")\n",
    "    \n",
    "    with ThreadContext(name=\"demo_conversation\", metadata={\"session\": \"demo\"}) as thread:\n",
    "        # Simulate conversation turns\n",
    "        \n",
    "        # Turn 1\n",
    "        thread.add_message(\"user\", \"Hello, can you help me with AI observability?\")\n",
    "        print(\"üë§ User: Hello, can you help me with AI observability?\")\n",
    "        \n",
    "        # Simulate LLM response within thread\n",
    "        with trace_llm_call(model=\"gpt-4\") as llm_span:\n",
    "            time.sleep(0.3)\n",
    "            response1 = \"I'd be happy to help you with AI observability!\"\n",
    "            thread.add_message(\"assistant\", response1)\n",
    "            print(f\"ü§ñ Assistant: {response1}\")\n",
    "        \n",
    "        # Turn 2  \n",
    "        thread.add_message(\"user\", \"What are the key components?\")\n",
    "        print(\"üë§ User: What are the key components?\")\n",
    "        \n",
    "        with trace_llm_call(model=\"gpt-4\") as llm_span:\n",
    "            time.sleep(0.4)\n",
    "            response2 = \"Key components include tracing, metrics, and logging.\"\n",
    "            thread.add_message(\"assistant\", response2)\n",
    "            print(f\"ü§ñ Assistant: {response2}\")\n",
    "        \n",
    "        # Get thread statistics\n",
    "        stats = thread.get_statistics()\n",
    "        print(f\"\\\\nüìä Thread Stats: {stats['message_count']} messages, {stats['turn_count']} turns\")\n",
    "\n",
    "# Test all context manager and streaming features\n",
    "print(\"üîÑ Testing Context Managers and Streaming...\")\n",
    "\n",
    "# Test context managers\n",
    "print(\"\\\\n1Ô∏è‚É£ Context Manager Examples:\")\n",
    "query_result = process_user_query_with_context_managers(\"What are the benefits of AI observability?\")\n",
    "\n",
    "agent_result = agent_task_with_context_manager(\"Analyze system performance metrics\")\n",
    "\n",
    "operation_result = complex_operation_with_tracing()\n",
    "\n",
    "# Test streaming\n",
    "print(\"\\\\n2Ô∏è‚É£ Streaming Examples:\")\n",
    "stream_result = test_streaming_with_context_manager(\"Explain machine learning concepts\")\n",
    "\n",
    "# Test thread context\n",
    "print(\"\\\\n3Ô∏è‚É£ Thread Context Examples:\")\n",
    "test_thread_context_conversation()\n",
    "\n",
    "print(\"\\\\n‚úÖ Context managers and streaming testing completed!\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## ‚úÖ FIXED: Correct trace_operation Usage\n",
    "\n",
    "The `trace_operation()` context manager has been fixed with the correct syntax:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORRECTED trace_operation Examples\n",
    "# The correct syntax is: trace_operation(operation_name, attributes=dict, tags=dict)\n",
    "\n",
    "def test_correct_trace_operation_usage():\n",
    "    \"\"\"Demonstrate the CORRECT syntax for trace_operation context manager.\"\"\"\n",
    "    print(\"üîß Testing CORRECT trace_operation usage...\")\n",
    "    \n",
    "    # ‚úÖ CORRECT: First parameter is operation_name (string), second is attributes (dict)\n",
    "    with trace_operation(\"data_processing_pipeline\", \n",
    "                        attributes={\"operation_type\": \"data_pipeline\", \"complexity\": \"high\"}) as span:\n",
    "        # Step 1: Data loading\n",
    "        print(\"üì• Step 1: Loading data...\")\n",
    "        time.sleep(0.2)\n",
    "        span.set_attributes({\"step\": \"data_loading\", \"records_loaded\": 1000})\n",
    "        \n",
    "        # Step 2: Processing\n",
    "        print(\"‚öôÔ∏è  Step 2: Processing data...\")\n",
    "        time.sleep(0.3)\n",
    "        span.set_attributes({\"step\": \"processing\", \"records_processed\": 950})\n",
    "        \n",
    "        # Step 3: Output\n",
    "        print(\"üì§ Step 3: Generating output...\")\n",
    "        time.sleep(0.1)\n",
    "        span.set_attributes({\"step\": \"output\", \"records_output\": 950})\n",
    "        \n",
    "        result = {\n",
    "            \"operation\": \"data_processing_pipeline\",\n",
    "            \"input_records\": 1000,\n",
    "            \"processed_records\": 950,\n",
    "            \"success\": True\n",
    "        }\n",
    "        \n",
    "        print(\"‚úÖ Complex operation completed successfully\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "def test_correct_batch_operations():\n",
    "    \"\"\"Demonstrate correct trace_operation usage in batch processing.\"\"\"\n",
    "    print(\"üì¶ Testing CORRECT batch trace_operation usage...\")\n",
    "    \n",
    "    operations = []\n",
    "    \n",
    "    for i in range(3):  # Reduced to 3 for demo\n",
    "        # ‚úÖ CORRECT: operation_name first, then attributes dict\n",
    "        with trace_operation(f\"batch_operation_{i}\", \n",
    "                           attributes={\"operation_type\": \"batch_demo\", \"batch_index\": i}) as span:\n",
    "            span.set_attributes({\n",
    "                \"batch.operation_number\": i,\n",
    "                \"batch.total_operations\": 3,\n",
    "                \"operation.size\": \"small\"\n",
    "            })\n",
    "            time.sleep(0.1)  # Quick operations\n",
    "            operations.append(f\"operation_{i}\")\n",
    "            print(f\"üî∏ Batch operation {i+1}/3 completed\")\n",
    "    \n",
    "    print(f\"‚úÖ Batch processing completed: {len(operations)} operations\")\n",
    "    return operations\n",
    "\n",
    "# Test the corrected functions\n",
    "print(\"üîß Testing CORRECTED Context Manager Usage...\")\n",
    "\n",
    "print(\"\\\\n1Ô∏è‚É£ Correct trace_operation Usage:\")\n",
    "operation_result = test_correct_trace_operation_usage()\n",
    "\n",
    "print(\"\\\\n2Ô∏è‚É£ Correct Batch Operations:\")\n",
    "batch_result = test_correct_batch_operations()\n",
    "\n",
    "print(f\"\\\\n‚úÖ All corrected context manager examples completed!\")\n",
    "print(f\"Operation result: {operation_result['success']}\")\n",
    "print(f\"Batch operations: {len(batch_result)} completed\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## ‚úÖ FIXED: Correct create_traced_agent Usage\n",
    "\n",
    "The `create_traced_agent()` function has been fixed with the correct parameters:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORRECTED create_traced_agent Example\n",
    "# The correct signature is: create_traced_agent(agent, agent_type, capabilities, trace_config)\n",
    "\n",
    "def test_traced_agent_proxy_corrected():\n",
    "    \"\"\"Test traced agent proxy with CORRECT parameters.\"\"\"\n",
    "    print(\"ü§ñ Testing Traced Agent Proxy (CORRECTED)...\")\n",
    "    \n",
    "    # Mock agent class\n",
    "    class MockAgent:\n",
    "        def __init__(self, name: str):\n",
    "            self.name = name\n",
    "        \n",
    "        def think(self, problem: str) -> str:\n",
    "            time.sleep(0.2)\n",
    "            return f\"Thinking about: {problem}\"\n",
    "        \n",
    "        def act(self, action: str) -> str:\n",
    "            time.sleep(0.3)\n",
    "            return f\"Performing action: {action}\"\n",
    "        \n",
    "        def plan(self, goal: str) -> List[str]:\n",
    "            time.sleep(0.4)\n",
    "            return [f\"Step 1 for {goal}\", f\"Step 2 for {goal}\", f\"Step 3 for {goal}\"]\n",
    "    \n",
    "    # ‚úÖ CORRECT: Use proper parameter names and structure\n",
    "    original_agent = MockAgent(\"demo_agent\")\n",
    "    traced_agent = create_traced_agent(\n",
    "        agent=original_agent,\n",
    "        agent_type=\"traced_demo_agent\",  # ‚úÖ CORRECT: agent_type (not agent_id)\n",
    "        capabilities=[\"thinking\", \"acting\", \"planning\"],  # ‚úÖ CORRECT: capabilities (not auto_trace_methods)\n",
    "        trace_config={\"capture_inputs\": True, \"capture_outputs\": True}  # ‚úÖ CORRECT: trace_config dict\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Traced agent proxy created successfully!\")\n",
    "    \n",
    "    # Test traced methods\n",
    "    print(\"üß† Testing traced agent methods...\")\n",
    "    \n",
    "    thought = traced_agent.think(\"How to improve AI observability\")\n",
    "    print(f\"üí≠ Think result: {thought}\")\n",
    "    \n",
    "    action = traced_agent.act(\"Implement monitoring dashboard\")\n",
    "    print(f\"‚ö° Action result: {action}\")\n",
    "    \n",
    "    plan = traced_agent.plan(\"Enhance system reliability\")\n",
    "    print(f\"üìã Plan result: {len(plan)} steps\")\n",
    "    \n",
    "    return traced_agent\n",
    "\n",
    "def test_traced_openai_client_corrected():\n",
    "    \"\"\"Test traced OpenAI client with CORRECT parameters.\"\"\"\n",
    "    print(\"üîÑ Testing Traced OpenAI Client (CORRECTED)...\")\n",
    "    \n",
    "    # ‚úÖ CORRECT: Use actual OpenAI client instance, not direct parameters\n",
    "    try:\n",
    "        # First create a real OpenAI client (even with mock key)\n",
    "        import openai\n",
    "        original_client = openai.OpenAI(api_key=\"mock-key-for-demo\")\n",
    "        \n",
    "        # ‚úÖ CORRECT: Pass the client instance to the tracer\n",
    "        traced_client = create_traced_openai_client(\n",
    "            original_client=original_client,\n",
    "            trace_config={\"trace_completions\": True, \"capture_content\": True}\n",
    "        )\n",
    "        print(\"‚úÖ Traced OpenAI client created successfully!\")\n",
    "        \n",
    "        # Mock a call (won't actually work without real API key)\n",
    "        print(\"ü§ñ Simulating traced OpenAI call...\")\n",
    "        print(\"‚ÑπÔ∏è  Would automatically trace all OpenAI API calls\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ÑπÔ∏è  Traced client demo: {e}\")\n",
    "        print(\"üìù Note: This requires a real OpenAI client instance\")\n",
    "\n",
    "# Test the corrected functions\n",
    "print(\"üöÄ Testing CORRECTED Proxy Object Functions...\")\n",
    "\n",
    "print(\"\\\\n1Ô∏è‚É£ Corrected Traced Agent:\")\n",
    "traced_agent = test_traced_agent_proxy_corrected()\n",
    "\n",
    "print(\"\\\\n2Ô∏è‚É£ Corrected Traced OpenAI Client:\")\n",
    "test_traced_openai_client_corrected()\n",
    "\n",
    "print(\"\\\\n‚úÖ All corrected proxy object examples completed!\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## üîÑ FINAL COMPREHENSIVE FLUSH\n",
    "\n",
    "Final flush to ensure all traces from the entire demo are sent to your endpoint.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## üîß FIXED: Enhanced SDK Initialization with Endpoint Debugging\n",
    "\n",
    "The endpoint configuration has been fixed with proper debugging and transport settings:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîß ENHANCED SDK INITIALIZATION WITH ENDPOINT DEBUGGING\n",
    "import noveum_trace\n",
    "from noveum_trace import trace, trace_agent, trace_llm, trace_tool\n",
    "import logging\n",
    "import sys\n",
    "import requests\n",
    "\n",
    "# üîç COMPREHENSIVE DEBUGGING SETUP\n",
    "print(\"üîß Setting up enhanced debugging for transport layer...\")\n",
    "\n",
    "# Set up comprehensive logging with detailed output\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG, \n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[logging.StreamHandler(sys.stdout)]\n",
    ")\n",
    "\n",
    "# Enable specific loggers for transport debugging\n",
    "loggers_to_enable = [\n",
    "    'noveum_trace.transport', \n",
    "    'noveum_trace.transport.http_transport',\n",
    "    'urllib3.connectionpool'\n",
    "]\n",
    "\n",
    "for logger_name in loggers_to_enable:\n",
    "    logger = logging.getLogger(logger_name)\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "\n",
    "print(\"‚úÖ Enhanced debugging enabled\")\n",
    "\n",
    "# üåê ENDPOINT VERIFICATION \n",
    "def verify_endpoint():\n",
    "    \\\"\\\"\\\"Verify that the Beeceptor endpoint is reachable.\\\"\\\"\\\"\n",
    "    endpoint = \"https://noveum-trace.free.beeceptor.com\"\n",
    "    \n",
    "    print(f\"üîç Verifying endpoint reachability: {endpoint}\")\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(endpoint, timeout=10)\n",
    "        print(f\"‚úÖ Base endpoint reachable - Status: {response.status_code}\")\n",
    "        \n",
    "        # Test the actual trace endpoints\n",
    "        trace_endpoints = [\n",
    "            f\"{endpoint}/v1/trace\",   # Single trace endpoint\n",
    "            f\"{endpoint}/v1/traces\"   # Batch trace endpoint  \n",
    "        ]\n",
    "        \n",
    "        for test_endpoint in trace_endpoints:\n",
    "            try:\n",
    "                test_response = requests.head(test_endpoint, timeout=5)\n",
    "                print(f\"üì° {test_endpoint} - Status: {test_response.status_code}\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è  {test_endpoint} - Error: {e}\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Endpoint verification failed: {e}\")\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Verify endpoint first\n",
    "endpoint_ok = verify_endpoint()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üöÄ ENHANCED SDK INITIALIZATION\n",
    "try:\n",
    "    print(\"\\\\nüöÄ Initializing Noveum Trace SDK with enhanced configuration...\")\n",
    "    \n",
    "    # üìã Display endpoint mapping\n",
    "    base_endpoint = \"https://api.noveum.ai/api\"\n",
    "    print(f\"üåê Base Endpoint: {base_endpoint}\")\n",
    "    print(f\"üì° Single Trace Endpoint: {base_endpoint}/v1/trace\")\n",
    "    print(f\"üì¶ Batch Trace Endpoint: {base_endpoint}/v1/traces\")\n",
    "    print(f\"üîß Transport Mode: Individual traces (batch_size=1) for better debugging\")\n",
    "    \n",
    "    noveum_trace.init(\n",
    "        api_key=os.getenv('NOVEUM_API_KEY'),\n",
    "        project=\"jupyter-test-project\",\n",
    "        environment=\"development\", \n",
    "        endpoint=base_endpoint,  # SDK will append /v1/trace or /v1/traces automatically\n",
    "        debug=True,  # Enable debug mode\n",
    "        \n",
    "        # üîß Enhanced transport configuration for debugging\n",
    "        transport_config={\n",
    "            \"timeout\": 30,           # 30 second timeout (generous for debugging)\n",
    "            \"retry_attempts\": 0,     # No retries for faster debugging feedback  \n",
    "            \"batch_size\": 1,         # Send traces individually (not batched)\n",
    "            \"batch_timeout\": 0.5,    # Send traces immediately\n",
    "            \"compression\": False,    # No compression for easier debugging\n",
    "            \"verify_ssl\": True       # Verify SSL certificates\n",
    "        },\n",
    "        \n",
    "        # ‚úÖ Comprehensive tracing configuration  \n",
    "        tracing_config={\n",
    "            \"sample_rate\": 1.0,        # Trace 100% of operations\n",
    "            \"capture_errors\": True,    # Capture error details\n",
    "            \"auto_flush\": True         # Automatically flush traces\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Noveum Trace SDK initialized successfully!\")\n",
    "    \n",
    "    # üìä Display configuration details\n",
    "    config = noveum_trace.get_config()\n",
    "    print(f\"üìä Project: {config.project}\")\n",
    "    print(f\"üîß Environment: {config.environment}\")\n",
    "    print(f\"üåê Transport Endpoint: {config.transport.endpoint}\")\n",
    "    print(f\"üì¶ Batch Size: {config.transport.batch_size}\")\n",
    "    print(f\"‚è±Ô∏è  Batch Timeout: {config.transport.batch_timeout}s\")\n",
    "    print(f\"üîç Debug Mode: {config.debug}\")\n",
    "    \n",
    "    print(\"\\\\nüéØ SDK initialization completed!\")\n",
    "    print(\"üìã Check the debug log output above for HTTP request details\")\n",
    "    print(\"üåê Your traces should now be visible at: \" + base_endpoint)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error initializing SDK: {e}\")\n",
    "    print(\"Continuing with demo - traces will be logged locally\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## üîß Debug: Testing Endpoint Connectivity\n",
    "\n",
    "Let's test if traces are being sent to your configured endpoint and diagnose any issues.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 7.2: Auto-Instrumentation and Advanced Features\n",
    "\n",
    "Test auto-instrumentation, proxy objects, and advanced SDK features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import advanced features\n",
    "from noveum_trace import (\n",
    "    auto_instrument, get_instrumented_libraries, is_instrumented,\n",
    "    create_traced_openai_client, create_traced_agent, TracedOpenAIClient,\n",
    "    start_trace, start_span, get_current_trace, get_current_span\n",
    ")\n",
    "\n",
    "# Auto-Instrumentation Examples\n",
    "\n",
    "def test_auto_instrumentation():\n",
    "    \"\"\"Test automatic instrumentation of libraries.\"\"\"\n",
    "    print(\"üîß Testing Auto-Instrumentation...\")\n",
    "    \n",
    "    # Check available instrumentations\n",
    "    available = noveum_trace.get_available_instrumentations()\n",
    "    print(f\"üì¶ Available instrumentations: {available}\")\n",
    "    \n",
    "    # Enable auto-instrumentation for OpenAI (if not already enabled)\n",
    "    if not is_instrumented(\"openai\"):\n",
    "        print(\"üîå Enabling OpenAI auto-instrumentation...\")\n",
    "        try:\n",
    "            auto_instrument(\"openai\")\n",
    "            print(\"‚úÖ OpenAI auto-instrumentation enabled\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  Auto-instrumentation: {e}\")\n",
    "    else:\n",
    "        print(\"‚úÖ OpenAI already instrumented\")\n",
    "    \n",
    "    # Check instrumented libraries\n",
    "    instrumented = get_instrumented_libraries()\n",
    "    print(f\"üîç Currently instrumented: {instrumented}\")\n",
    "    \n",
    "    return instrumented\n",
    "\n",
    "# Proxy Objects for Enhanced Control\n",
    "\n",
    "def test_traced_openai_client():\n",
    "    \"\"\"Test traced OpenAI client proxy.\"\"\"\n",
    "    print(\"üîÑ Testing Traced OpenAI Client...\")\n",
    "    \n",
    "    # Create traced OpenAI client (even without real API key)\n",
    "    try:\n",
    "        traced_client = create_traced_openai_client(\n",
    "            api_key=\"mock-key-for-demo\",\n",
    "            trace_completions=True,\n",
    "            trace_embeddings=True,\n",
    "            capture_content=True\n",
    "        )\n",
    "        print(\"‚úÖ Traced OpenAI client created\")\n",
    "        \n",
    "        # Mock a call (won't actually work without real API key)\n",
    "        print(\"ü§ñ Simulating traced OpenAI call...\")\n",
    "        # In real usage: response = traced_client.chat.completions.create(...)\n",
    "        print(\"‚ÑπÔ∏è  Would automatically trace all OpenAI API calls\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ÑπÔ∏è  Traced client demo: {e}\")\n",
    "\n",
    "def test_traced_agent_proxy():\n",
    "    \"\"\"Test traced agent proxy for enhanced agent monitoring.\"\"\"\n",
    "    print(\"ü§ñ Testing Traced Agent Proxy...\")\n",
    "    \n",
    "    # Mock agent class\n",
    "    class MockAgent:\n",
    "        def __init__(self, name: str):\n",
    "            self.name = name\n",
    "        \n",
    "        def think(self, problem: str) -> str:\n",
    "            time.sleep(0.2)\n",
    "            return f\"Thinking about: {problem}\"\n",
    "        \n",
    "        def act(self, action: str) -> str:\n",
    "            time.sleep(0.3)\n",
    "            return f\"Performing action: {action}\"\n",
    "        \n",
    "        def plan(self, goal: str) -> List[str]:\n",
    "            time.sleep(0.4)\n",
    "            return [f\"Step 1 for {goal}\", f\"Step 2 for {goal}\", f\"Step 3 for {goal}\"]\n",
    "    \n",
    "    # Create traced agent proxy\n",
    "    original_agent = MockAgent(\"demo_agent\")\n",
    "    traced_agent = create_traced_agent(\n",
    "        agent=original_agent,\n",
    "        auto_trace_methods=[\"think\", \"act\", \"plan\"],\n",
    "        capture_inputs=True,\n",
    "        capture_outputs=True\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Traced agent proxy created\")\n",
    "    \n",
    "    # Test traced methods\n",
    "    print(\"üß† Testing traced agent methods...\")\n",
    "    \n",
    "    thought = traced_agent.think(\"How to improve AI observability\")\n",
    "    print(f\"üí≠ Think result: {thought}\")\n",
    "    \n",
    "    action = traced_agent.act(\"Implement monitoring dashboard\")\n",
    "    print(f\"‚ö° Action result: {action}\")\n",
    "    \n",
    "    plan = traced_agent.plan(\"Enhance system reliability\")\n",
    "    print(f\"üìã Plan result: {len(plan)} steps\")\n",
    "\n",
    "# Manual Span Creation and Management\n",
    "\n",
    "def test_manual_tracing():\n",
    "    \"\"\"Test manual trace and span creation.\"\"\"\n",
    "    print(\"üîç Testing Manual Tracing...\")\n",
    "    \n",
    "    # Start a manual trace\n",
    "    trace = start_trace(\"manual_demo_trace\")\n",
    "    print(f\"‚úÖ Started trace: {trace.trace_id}\")\n",
    "    \n",
    "    # Create nested spans manually\n",
    "    with trace.span(\"parent_operation\") as parent_span:\n",
    "        parent_span.set_attributes({\n",
    "            \"operation.type\": \"parent\",\n",
    "            \"operation.importance\": \"high\"\n",
    "        })\n",
    "        print(\"üìä Parent span created\")\n",
    "        \n",
    "        # Child span 1\n",
    "        with parent_span.create_child_span(\"child_operation_1\") as child1:\n",
    "            child1.set_attributes({\n",
    "                \"operation.type\": \"child\",\n",
    "                \"child.number\": 1\n",
    "            })\n",
    "            time.sleep(0.2)\n",
    "            print(\"üîπ Child span 1 completed\")\n",
    "        \n",
    "        # Child span 2  \n",
    "        with parent_span.create_child_span(\"child_operation_2\") as child2:\n",
    "            child2.set_attributes({\n",
    "                \"operation.type\": \"child\",\n",
    "                \"child.number\": 2,\n",
    "                \"child.data_processed\": 500\n",
    "            })\n",
    "            time.sleep(0.3)\n",
    "            print(\"üîπ Child span 2 completed\")\n",
    "        \n",
    "        print(\"üìä Parent operation completed\")\n",
    "    \n",
    "    # Finish trace\n",
    "    trace.finish()\n",
    "    print(f\"‚úÖ Manual trace completed: {trace.trace_id}\")\n",
    "\n",
    "# Advanced Configuration and Performance Features\n",
    "\n",
    "def test_advanced_configuration():\n",
    "    \"\"\"Test advanced SDK configuration options.\"\"\"\n",
    "    print(\"‚öôÔ∏è  Testing Advanced Configuration...\")\n",
    "    \n",
    "    # Get current configuration\n",
    "    config = noveum_trace.get_config()\n",
    "    print(f\"üìã Current project: {config.project}\")\n",
    "    print(f\"üåê Current endpoint: {config.transport.endpoint}\")\n",
    "    print(f\"üì¶ Batch size: {config.transport.batch_size}\")\n",
    "    print(f\"‚è±Ô∏è  Batch timeout: {config.transport.batch_timeout}\")\n",
    "    \n",
    "    # Test configuration updates (temporary for demo)\n",
    "    original_debug = config.debug\n",
    "    \n",
    "    # Temporarily enable debug mode\n",
    "    noveum_trace.configure(debug=True)\n",
    "    print(\"üêõ Debug mode enabled temporarily\")\n",
    "    \n",
    "    # Create a trace to demonstrate debug output\n",
    "    with noveum_trace.trace_operation(\"debug_demo_operation\") as span:\n",
    "        span.set_attributes({\"demo\": \"configuration\", \"debug_enabled\": True})\n",
    "        time.sleep(0.1)\n",
    "        print(\"‚úÖ Debug operation completed\")\n",
    "    \n",
    "    # Restore original debug setting\n",
    "    noveum_trace.configure(debug=original_debug)\n",
    "    print(f\"üîß Debug mode restored to: {original_debug}\")\n",
    "\n",
    "# Batch Processing and Performance Monitoring\n",
    "\n",
    "def test_batch_processing():\n",
    "    \"\"\"Test batch operations for performance.\"\"\"\n",
    "    print(\"üì¶ Testing Batch Processing...\")\n",
    "    \n",
    "    # Create multiple operations quickly to test batching\n",
    "    operations = []\n",
    "    \n",
    "    for i in range(5):\n",
    "        with noveum_trace.trace_operation(f\"batch_operation_{i}\", operation_type=\"batch_demo\") as span:\n",
    "            span.set_attributes({\n",
    "                \"batch.operation_number\": i,\n",
    "                \"batch.total_operations\": 5,\n",
    "                \"operation.size\": \"small\"\n",
    "            })\n",
    "            time.sleep(0.05)  # Quick operations\n",
    "            operations.append(f\"operation_{i}\")\n",
    "            print(f\"üî∏ Batch operation {i+1}/5 completed\")\n",
    "    \n",
    "    print(f\"‚úÖ Batch processing completed: {len(operations)} operations\")\n",
    "    \n",
    "    # Force flush to send batched traces\n",
    "    try:\n",
    "        noveum_trace.flush()\n",
    "        print(\"üì§ Forced flush of batched traces\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ÑπÔ∏è  Flush status: {e}\")\n",
    "\n",
    "# Error Handling and Edge Cases\n",
    "\n",
    "def test_error_handling():\n",
    "    \"\"\"Test error handling and edge cases.\"\"\"\n",
    "    print(\"‚ö†Ô∏è  Testing Error Handling...\")\n",
    "    \n",
    "    # Test error capture in traced function\n",
    "    @noveum_trace.trace(capture_errors=True, capture_stack_trace=True)\n",
    "    def operation_with_error(should_fail: bool = False):\n",
    "        if should_fail:\n",
    "            raise ValueError(\"This is a demo error for testing\")\n",
    "        return \"Success!\"\n",
    "    \n",
    "    # Test successful operation\n",
    "    try:\n",
    "        result = operation_with_error(should_fail=False)\n",
    "        print(f\"‚úÖ Successful operation: {result}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Unexpected error: {e}\")\n",
    "    \n",
    "    # Test error capture\n",
    "    try:\n",
    "        result = operation_with_error(should_fail=True)\n",
    "        print(f\"Unexpected success: {result}\")\n",
    "    except ValueError as e:\n",
    "        print(f\"‚úÖ Error captured successfully: {e}\")\n",
    "\n",
    "# Run all advanced feature tests\n",
    "print(\"üöÄ Testing Auto-Instrumentation and Advanced Features...\")\n",
    "\n",
    "print(\"\\\\n1Ô∏è‚É£ Auto-Instrumentation:\")\n",
    "instrumented_libs = test_auto_instrumentation()\n",
    "\n",
    "print(\"\\\\n2Ô∏è‚É£ Proxy Objects:\")\n",
    "test_traced_openai_client()\n",
    "test_traced_agent_proxy()\n",
    "\n",
    "print(\"\\\\n3Ô∏è‚É£ Manual Tracing:\")\n",
    "test_manual_tracing()\n",
    "\n",
    "print(\"\\\\n4Ô∏è‚É£ Advanced Configuration:\")\n",
    "test_advanced_configuration()\n",
    "\n",
    "print(\"\\\\n5Ô∏è‚É£ Batch Processing:\")\n",
    "test_batch_processing()\n",
    "\n",
    "print(\"\\\\n6Ô∏è‚É£ Error Handling:\")\n",
    "test_error_handling()\n",
    "\n",
    "print(\"\\\\n‚úÖ Advanced features testing completed!\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 6: Multi-Agent System\n",
    "\n",
    "Test multi-agent workflow tracing with the `@trace_agent` decorator.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@trace_agent(agent_id=\"research_agent\")\n",
    "def research_agent(query: str) -> Dict[str, Any]:\n",
    "    \"\"\"Research agent that gathers information.\"\"\"\n",
    "    print(f\"üîç Research Agent: Processing query '{query}'\")\n",
    "\n",
    "    # Simulate research process\n",
    "    time.sleep(0.4)\n",
    "\n",
    "    # Mock research findings\n",
    "    findings = {\n",
    "        \"query\": query,\n",
    "        \"sources\": [\"source1.pdf\", \"source2.html\", \"source3.json\"],\n",
    "        \"key_points\": [\n",
    "            \"Point 1: Observability improves system reliability\",\n",
    "            \"Point 2: Tracing helps identify bottlenecks\",\n",
    "            \"Point 3: Monitoring enables proactive maintenance\"\n",
    "        ],\n",
    "        \"confidence\": 0.87,\n",
    "        \"research_time\": \"0.4s\"\n",
    "    }\n",
    "\n",
    "    print(f\"‚úÖ Research completed with {len(findings['sources'])} sources\")\n",
    "    return findings\n",
    "\n",
    "@trace_agent(agent_id=\"orchestrator\")\n",
    "def orchestrate_workflow(task: str) -> Dict[str, Any]:\n",
    "    \"\"\"Orchestrator agent that coordinates multiple agents.\"\"\"\n",
    "    print(f\"üé≠ Orchestrator: Starting workflow for task '{task}'\")\n",
    "\n",
    "    # Step 1: Research\n",
    "    print(\"\\nüîç Step 1: Research Phase\")\n",
    "    research_data = research_agent(task)\n",
    "\n",
    "    # Step 2: Analysis (simplified)\n",
    "    print(\"\\nüìä Step 2: Analysis Phase\")\n",
    "    analysis_data = {\n",
    "        \"insights\": [\"Observability is crucial\", \"Tracing provides insights\"],\n",
    "        \"quality_score\": 0.89\n",
    "    }\n",
    "\n",
    "    # Final orchestration result\n",
    "    workflow_result = {\n",
    "        \"task\": task,\n",
    "        \"workflow_id\": \"wf-001\",\n",
    "        \"phases_completed\": 2,\n",
    "        \"research_summary\": research_data[\"key_points\"],\n",
    "        \"analysis_summary\": analysis_data[\"insights\"],\n",
    "        \"overall_confidence\": research_data[\"confidence\"],\n",
    "        \"total_time\": \"1.0s\"\n",
    "    }\n",
    "\n",
    "    print(\"\\n‚úÖ Orchestrator: Workflow completed successfully\")\n",
    "    return workflow_result\n",
    "\n",
    "# Test the multi-agent workflow\n",
    "task = \"Analyze the importance of observability in AI systems\"\n",
    "workflow_result = orchestrate_workflow(task)\n",
    "print(\"\\nüé≠ Final Workflow Result:\")\n",
    "print(f\"Task: {workflow_result['task']}\")\n",
    "print(f\"Confidence: {workflow_result['overall_confidence']:.2f}\")\n",
    "print(f\"Phases: {workflow_result['phases_completed']}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 7: Tool Tracing\n",
    "\n",
    "Test tool tracing with the `@trace_tool` decorator.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@trace_tool(tool_name=\"calculator\")\n",
    "def calculate(operation: str, a: float, b: float) -> Dict[str, Any]:\n",
    "    \"\"\"A calculator tool with tracing.\"\"\"\n",
    "    print(f\"üî¢ Calculator: Performing {operation} on {a} and {b}\")\n",
    "\n",
    "    operations = {\n",
    "        \"add\": lambda x, y: x + y,\n",
    "        \"subtract\": lambda x, y: x - y,\n",
    "        \"multiply\": lambda x, y: x * y,\n",
    "        \"divide\": lambda x, y: x / y if y != 0 else None\n",
    "    }\n",
    "\n",
    "    if operation not in operations:\n",
    "        return {\"error\": f\"Unknown operation: {operation}\"}\n",
    "\n",
    "    try:\n",
    "        result = operations[operation](a, b)\n",
    "        if result is None:\n",
    "            return {\"error\": \"Division by zero\"}\n",
    "\n",
    "        return {\n",
    "            \"operation\": operation,\n",
    "            \"operands\": [a, b],\n",
    "            \"result\": result,\n",
    "            \"success\": True\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e), \"success\": False}\n",
    "\n",
    "@trace_tool(tool_name=\"text_analyzer\")\n",
    "def analyze_text(text: str) -> Dict[str, Any]:\n",
    "    \"\"\"Text analysis tool with tracing.\"\"\"\n",
    "    print(f\"üìù Text Analyzer: Analyzing text of length {len(text)}\")\n",
    "\n",
    "    # Simulate analysis\n",
    "    time.sleep(0.2)\n",
    "\n",
    "    analysis = {\n",
    "        \"text_length\": len(text),\n",
    "        \"word_count\": len(text.split()),\n",
    "        \"sentence_count\": text.count('.') + text.count('!') + text.count('?'),\n",
    "        \"avg_word_length\": sum(len(word) for word in text.split()) / len(text.split()) if text.split() else 0\n",
    "    }\n",
    "\n",
    "    print(f\"‚úÖ Analysis complete: {analysis['word_count']} words, {analysis['sentence_count']} sentences\")\n",
    "    return analysis\n",
    "\n",
    "# Test tool tracing\n",
    "calc_result = calculate(\"multiply\", 15, 4)\n",
    "print(f\"\\nüî¢ Calculator Result: {calc_result}\")\n",
    "\n",
    "text_to_analyze = \"This is a sample text for testing the noveum-trace SDK. It contains multiple sentences!\"\n",
    "text_analysis = analyze_text(text_to_analyze)\n",
    "print(f\"\\nüìù Text Analysis Result: {text_analysis}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 8: Summary and Cleanup\n",
    "\n",
    "Test summary and cleanup of resources.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pkg_resources\n",
    "\n",
    "# Test summary\n",
    "def print_test_summary():\n",
    "    \"\"\"Print a summary of all tests performed.\"\"\"\n",
    "    print(\"üìã NOVEUM TRACE SDK TEST SUMMARY\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # Check SDK version\n",
    "    try:\n",
    "        version = pkg_resources.get_distribution(\"noveum-trace\").version\n",
    "        print(f\"‚úÖ SDK Version: {version}\")\n",
    "    except:\n",
    "        print(\"‚ö†Ô∏è  Could not determine SDK version\")\n",
    "\n",
    "    # Environment check\n",
    "    print(f\"‚úÖ Python Version: {sys.version.split()[0]}\")\n",
    "    print(f\"‚úÖ Environment Variables: {'‚úì' if os.getenv('NOVEUM_API_KEY') else '‚úó'}\")\n",
    "\n",
    "    # Features tested\n",
    "    features_tested = [\n",
    "        \"Basic function tracing (@trace)\",\n",
    "        \"LLM call tracing (@trace_llm)\",\n",
    "        \"Agent workflow tracing (@trace_agent)\",\n",
    "        \"Tool tracing (@trace_tool)\",\n",
    "        \"Multi-agent orchestration\",\n",
    "        \"Error handling\",\n",
    "        \"Framework integration simulation\"\n",
    "    ]\n",
    "\n",
    "    print(\"\\nüß™ Features Tested:\")\n",
    "    for feature in features_tested:\n",
    "        print(f\"  ‚úÖ {feature}\")\n",
    "\n",
    "    print(\"\\nüéØ Key Results:\")\n",
    "    print(\"  üîß All decorators: Functional\")\n",
    "    print(\"  ü§ñ Multi-agent support: Functional\")\n",
    "    print(\"  üîå Framework integration: Simulated successfully\")\n",
    "\n",
    "    print(\"\\n‚úÖ All tests completed successfully!\")\n",
    "    print(\"\\nüìñ Next Steps:\")\n",
    "    print(\"  1. Set up your actual NOVEUM_API_KEY for production use\")\n",
    "    print(\"  2. Integrate with your LLM applications\")\n",
    "    print(\"  3. Set up dashboards and monitoring\")\n",
    "    print(\"  4. Configure alerting based on trace data\")\n",
    "\n",
    "# Clean up function\n",
    "def cleanup_resources():\n",
    "    \"\"\"Clean up any resources created during testing.\"\"\"\n",
    "    print(\"üßπ Cleaning up test resources...\")\n",
    "\n",
    "    try:\n",
    "        # Attempt to flush any pending traces\n",
    "        noveum_trace.flush()\n",
    "        print(\"‚úÖ Traces flushed successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ÑπÔ∏è  Trace flush: {e}\")\n",
    "\n",
    "    print(\"‚úÖ Cleanup completed\")\n",
    "\n",
    "# Run summary and cleanup\n",
    "print_test_summary()\n",
    "cleanup_resources()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## üéâ Congratulations!\n",
    "\n",
    "You have successfully tested the Noveum Trace SDK from PyPI! \n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "- ‚úÖ Installation from PyPI\n",
    "- ‚úÖ Environment setup with proper API keys\n",
    "- ‚úÖ Basic function tracing with `@trace`\n",
    "- ‚úÖ LLM call tracing with `@trace_llm`\n",
    "- ‚úÖ Agent workflow tracing with `@trace_agent`\n",
    "- ‚úÖ Tool tracing with `@trace_tool`\n",
    "- ‚úÖ Multi-agent system orchestration\n",
    "- ‚úÖ Error handling and edge cases\n",
    "- ‚úÖ Performance considerations\n",
    "- ‚úÖ Framework integration patterns\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. **Production Setup**: Replace the dummy API key with your actual Noveum API key\n",
    "2. **Integration**: Integrate these patterns into your existing LLM applications\n",
    "3. **Monitoring**: Set up dashboards to monitor your traced applications\n",
    "4. **Optimization**: Use the trace data to optimize your application performance\n",
    "\n",
    "### Resources:\n",
    "\n",
    "- üìö [Noveum Trace Documentation](https://docs.noveum.ai)\n",
    "- üêô [GitHub Repository](https://github.com/Noveum/noveum-trace)\n",
    "- üì¶ [PyPI Package](https://pypi.org/project/noveum-trace/)\n",
    "\n",
    "Happy tracing! üöÄ\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
